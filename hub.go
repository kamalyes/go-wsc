/*
 * @Author: kamalyes 501893067@qq.com
 * @Date: 2025-11-13 00:00:00
 * @LastEditors: kamalyes 501893067@qq.com
 * @LastEditTime: 2025-12-12 13:58:59
 * @FilePath: \go-wsc\hub.go
 * @Description: WebSocket/SSE æœåŠ¡ç«¯ Hub - ç»Ÿä¸€ç®¡ç†å®æ—¶è¿æ¥
 *
 * Copyright (c) 2025 by kamalyes, All Rights Reserved.
 */

package wsc

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/gorilla/websocket"
	wscconfig "github.com/kamalyes/go-config/pkg/wsc"
	"github.com/kamalyes/go-toolbox/pkg/errorx"
	"github.com/kamalyes/go-toolbox/pkg/retry"
	"github.com/kamalyes/go-toolbox/pkg/safe"
)

// PoolManager è¿æ¥æ± ç®¡ç†å™¨æ¥å£ - ç”¨äºè§£è€¦ä¾èµ–
type PoolManager interface {
	// GetSMTPClient è·å–SMTPå®¢æˆ·ç«¯
	GetSMTPClient() interface{}
}

// SendFailureHandler æ¶ˆæ¯å‘é€å¤±è´¥å¤„ç†å™¨æ¥å£ - é€šç”¨å¤„ç†å™¨
type SendFailureHandler interface {
	// HandleSendFailure å¤„ç†æ¶ˆæ¯å‘é€å¤±è´¥
	HandleSendFailure(msg *HubMessage, recipient string, reason string, err error)
}

// QueueFullHandler é˜Ÿåˆ—æ»¡å¤„ç†å™¨
type QueueFullHandler interface {
	// HandleQueueFull å¤„ç†é˜Ÿåˆ—æ»¡çš„æƒ…å†µ
	HandleQueueFull(msg *HubMessage, recipient string, queueType string, err error)
}

// UserOfflineHandler ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
type UserOfflineHandler interface {
	// HandleUserOffline å¤„ç†ç”¨æˆ·ç¦»çº¿çš„æƒ…å†µ
	HandleUserOffline(msg *HubMessage, userID string, err error)
}

// ConnectionErrorHandler è¿æ¥é”™è¯¯å¤„ç†å™¨
type ConnectionErrorHandler interface {
	// HandleConnectionError å¤„ç†è¿æ¥é”™è¯¯
	HandleConnectionError(msg *HubMessage, clientID string, err error)
}

// TimeoutHandler è¶…æ—¶å¤„ç†å™¨
type TimeoutHandler interface {
	// HandleTimeout å¤„ç†è¶…æ—¶æƒ…å†µ
	HandleTimeout(msg *HubMessage, recipient string, timeoutType string, duration time.Duration, err error)
}

// HeartbeatTimeoutCallback å¿ƒè·³è¶…æ—¶å›è°ƒå‡½æ•°
// å‚æ•°: clientID - å®¢æˆ·ç«¯ID, userID - ç”¨æˆ·ID, lastHeartbeat - æœ€åå¿ƒè·³æ—¶é—´
type HeartbeatTimeoutCallback func(clientID string, userID string, lastHeartbeat time.Time)

// SendFailureReason æ¶ˆæ¯å‘é€å¤±è´¥åŸå› 
const (
	SendFailureReasonQueueFull     = "queue_full"     // é˜Ÿåˆ—æ»¡
	SendFailureReasonBroadcastFull = "broadcast_full" // å¹¿æ’­é˜Ÿåˆ—æ»¡
	SendFailureReasonPendingFull   = "pending_full"   // å¾…å‘é€é˜Ÿåˆ—æ»¡
	SendFailureReasonUserOffline   = "user_offline"   // ç”¨æˆ·ç¦»çº¿
	SendFailureReasonTimeout       = "timeout"        // è¶…æ—¶
	SendFailureReasonSendTimeout   = "send_timeout"   // å‘é€è¶…æ—¶
	SendFailureReasonAckTimeout    = "ack_timeout"    // ACKè¶…æ—¶
	SendFailureReasonConnClosed    = "conn_closed"    // è¿æ¥å…³é—­
	SendFailureReasonConnError     = "conn_error"     // è¿æ¥é”™è¯¯
	SendFailureReasonChannelClosed = "channel_closed" // é€šé“å…³é—­
	SendFailureReasonUnknown       = "unknown"        // æœªçŸ¥é”™è¯¯
	SendFailureReasonValidation    = "validation"     // éªŒè¯å¤±è´¥
	SendFailureReasonPermission    = "permission"     // æƒé™ä¸è¶³
)

// SendAttempt å‘é€å°è¯•è®°å½•
type SendAttempt struct {
	AttemptNumber int           // å°è¯•æ¬¡æ•°
	StartTime     time.Time     // å¼€å§‹æ—¶é—´
	Duration      time.Duration // è€—æ—¶
	Error         error         // é”™è¯¯
	Success       bool          // æ˜¯å¦æˆåŠŸ
}

// SendResult å‘é€ç»“æœ
type SendResult struct {
	Success      bool          // æœ€ç»ˆæ˜¯å¦æˆåŠŸ
	Attempts     []SendAttempt // æ‰€æœ‰å°è¯•è®°å½•
	TotalRetries int           // æ€»é‡è¯•æ¬¡æ•°
	TotalTime    time.Duration // æ€»è€—æ—¶
	FinalError   error         // æœ€ç»ˆé”™è¯¯
}

// ContextKey ä¸Šä¸‹æ–‡é”®ç±»å‹
type ContextKey string

const (
	// ContextKeyUserID ç”¨æˆ·IDä¸Šä¸‹æ–‡é”®
	ContextKeyUserID ContextKey = "user_id"
	// ContextKeySenderID å‘é€è€…IDä¸Šä¸‹æ–‡é”®
	ContextKeySenderID ContextKey = "sender_id"
)

// HubMessage Hubæ¶ˆæ¯ç»“æ„ï¼ˆå¤ç”¨ go-wsc ç±»å‹ï¼‰
type HubMessage struct {
	ID           string                 `json:"id"`                        // æ¶ˆæ¯IDï¼ˆç”¨äºACKï¼‰
	MessageType  MessageType            `json:"message_type"`              // æ¶ˆæ¯ç±»å‹
	Sender       string                 `json:"sender"`                    // å‘é€è€… (ä»ä¸Šä¸‹æ–‡è·å–)
	SenderType   UserType               `json:"sender_type"`               // å‘é€è€…ç±»å‹
	Receiver     string                 `json:"receiver"`                  // æ¥æ”¶è€…
	ReceiverType UserType               `json:"receiver_type"`             // æ¥æ”¶è€…ç±»å‹
	SessionID    string                 `json:"session_id"`                // ä¼šè¯ID
	Content      string                 `json:"content"`                   // æ¶ˆæ¯å†…å®¹
	Data         map[string]interface{} `json:"data,omitempty"`            // æ‰©å±•æ•°æ®
	CreateAt     time.Time              `json:"create_at"`                 // åˆ›å»ºæ—¶é—´
	MessageID    string                 `json:"message_id"`                // ä¸šåŠ¡æ¶ˆæ¯ID
	SeqNo        int64                  `json:"seq_no"`                    // æ¶ˆæ¯åºåˆ—å·
	Priority     Priority               `json:"priority"`                  // ä¼˜å…ˆçº§
	ReplyToMsgID string                 `json:"reply_to_msg_id,omitempty"` // å›å¤çš„æ¶ˆæ¯ID
	Status       MessageStatus          `json:"status"`                    // æ¶ˆæ¯çŠ¶æ€
	RequireAck   bool                   `json:"require_ack,omitempty"`     // æ˜¯å¦éœ€è¦ACKç¡®è®¤
}

// IsSystemMessage åˆ¤æ–­æ˜¯å¦ä¸ºç³»ç»Ÿæ¶ˆæ¯
func (m *HubMessage) IsSystemMessage() bool {
	return m.Sender == "system" || m.SenderType == UserTypeSystem
}

// Client å®¢æˆ·ç«¯è¿æ¥ï¼ˆæœåŠ¡ç«¯è§†è§’ï¼‰
type Client struct {
	ID            string                 // å®¢æˆ·ç«¯ID
	UserID        string                 // ç”¨æˆ·ID
	UserType      UserType               // ç”¨æˆ·ç±»å‹
	VIPLevel      VIPLevel               // VIPç­‰çº§
	Role          UserRole               // è§’è‰²
	ClientIP      string                 // å®¢æˆ·ç«¯IPåœ°å€
	Conn          *websocket.Conn        // WebSocketè¿æ¥
	LastSeen      time.Time              // æœ€åæ´»è·ƒæ—¶é—´
	LastHeartbeat time.Time              // æœ€åå¿ƒè·³æ—¶é—´
	Status        UserStatus             // çŠ¶æ€
	Department    Department             // éƒ¨é—¨
	Skills        []Skill                // æŠ€èƒ½
	MaxTickets    int                    // æœ€å¤§å·¥å•æ•°
	NodeID        string                 // èŠ‚ç‚¹ID
	ClientType    ClientType             // å®¢æˆ·ç«¯ç±»å‹
	Metadata      map[string]interface{} // å…ƒæ•°æ®
	SendChan      chan []byte            // å‘é€é€šé“
	Context       context.Context        // ä¸Šä¸‹æ–‡ï¼ˆå­˜å‚¨å‘é€è€…IDç­‰ä¿¡æ¯ï¼‰
}

// SSEConnection SSEè¿æ¥
type SSEConnection struct {
	UserID     string
	Writer     http.ResponseWriter
	Flusher    http.Flusher
	MessageCh  chan *HubMessage
	CloseCh    chan struct{}
	LastActive time.Time
	Context    context.Context // ä¸Šä¸‹æ–‡
}

// Hub WebSocket/SSE è¿æ¥ç®¡ç†ä¸­å¿ƒ
type Hub struct {
	// èŠ‚ç‚¹ä¿¡æ¯
	nodeID    string
	nodeInfo  *NodeInfo
	nodes     map[string]*NodeInfo
	startTime time.Time // Hub å¯åŠ¨æ—¶é—´

	// å®¢æˆ·ç«¯ç®¡ç†
	clients      map[string]*Client // æ‰€æœ‰å®¢æˆ·ç«¯ key: clientID
	userToClient map[string]*Client // ç”¨æˆ·IDåˆ°å®¢æˆ·ç«¯
	agentClients map[string]*Client // å®¢æœè¿æ¥

	// SSE è¿æ¥
	sseClients map[string]*SSEConnection

	// æ¶ˆæ¯é€šé“
	register    chan *Client
	unregister  chan *Client
	broadcast   chan *HubMessage
	nodeMessage chan *DistributedMessage

	// æ¶ˆæ¯ç¼“å†²é˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—æ»¡æ—¶é¢„å­˜ï¼‰
	pendingMessages chan *HubMessage
	maxPendingSize  int

	// ACKç®¡ç†å™¨
	ackManager *AckManager

	// æ¶ˆæ¯è®°å½•ç®¡ç†å™¨

	// æ¶ˆæ¯è®°å½•ä»“åº“ï¼ˆæ•°æ®åº“æŒä¹…åŒ–ï¼‰
	messageRecordRepo MessageRecordRepository

	// åœ¨çº¿çŠ¶æ€ä»“åº“ï¼ˆRedis åˆ†å¸ƒå¼å­˜å‚¨ï¼‰
	onlineStatusRepo OnlineStatusRepository

	// Hub ç»Ÿè®¡ä»“åº“ï¼ˆRedis åˆ†å¸ƒå¼ç»Ÿè®¡ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹ï¼‰
	statsRepo HubStatsRepository

	// è´Ÿè½½ç®¡ç†ä»“åº“ï¼ˆRedis åˆ†å¸ƒå¼å­˜å‚¨ï¼‰
	workloadRepo WorkloadRepository

	// å¹¶å‘æ§åˆ¶
	wg       sync.WaitGroup
	shutdown atomic.Bool
	started  atomic.Bool
	startCh  chan struct{}

	// æ¬¢è¿æ¶ˆæ¯æä¾›è€…
	welcomeProvider WelcomeMessageProvider

	// æ ¸å¿ƒç»„ä»¶
	logger WSCLogger // æ—¥å¿—å™¨

	// å¹¶å‘æ§åˆ¶
	mutex    sync.RWMutex
	sseMutex sync.RWMutex

	// æ¶ˆæ¯å‘é€å¤±è´¥å›è°ƒå¤„ç†å™¨
	sendFailureHandlers     []SendFailureHandler     // é€šç”¨å¤„ç†å™¨
	queueFullHandlers       []QueueFullHandler       // é˜Ÿåˆ—æ»¡å¤„ç†å™¨
	userOfflineHandlers     []UserOfflineHandler     // ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
	connectionErrorHandlers []ConnectionErrorHandler // è¿æ¥é”™è¯¯å¤„ç†å™¨
	timeoutHandlers         []TimeoutHandler         // è¶…æ—¶å¤„ç†å™¨
	failureHandlerMutex     sync.RWMutex             // å¤±è´¥å¤„ç†å™¨äº’æ–¥é”

	// å¿ƒè·³æœºåˆ¶
	heartbeatInterval       time.Duration            // å¿ƒè·³é—´éš”
	heartbeatTimeout        time.Duration            // å¿ƒè·³è¶…æ—¶æ—¶é—´
	heartbeatTimeoutHandler HeartbeatTimeoutCallback // å¿ƒè·³è¶…æ—¶å›è°ƒå‡½æ•°

	// ä¸Šä¸‹æ–‡
	ctx    context.Context
	cancel context.CancelFunc

	// é…ç½®
	config *wscconfig.WSC

	// æ€§èƒ½ä¼˜åŒ–ï¼šæ¶ˆæ¯å­—èŠ‚ç¼“å­˜æ± 
	msgPool sync.Pool

	// æ¶ˆæ¯é¢‘ç‡é™åˆ¶å™¨
	rateLimiter *RateLimiter

	// è¿æ¥æ± ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
	poolManager PoolManager
}

// DefaultHubConfig åˆ›å»ºé»˜è®¤Hubé…ç½®
// NodeInfo èŠ‚ç‚¹ä¿¡æ¯
type NodeInfo struct {
	ID          string     `json:"id"`
	IPAddress   string     `json:"ip_address"`
	Port        int        `json:"port"`
	Status      NodeStatus `json:"status"`
	LoadScore   float64    `json:"load_score"`
	LastSeen    time.Time  `json:"last_seen"`
	Connections int        `json:"connections"`
}

// NewHub åˆ›å»ºæ–°çš„Hub
func NewHub(config *wscconfig.WSC) *Hub {
	config = safe.MergeWithDefaults(config, wscconfig.Default())

	ctx, cancel := context.WithCancel(context.Background())
	nodeID := fmt.Sprintf("%s-%d", config.NodeIP, config.NodePort)

	hub := &Hub{
		nodeID:    nodeID,
		startTime: time.Now(),
		nodeInfo: &NodeInfo{
			ID:        nodeID,
			IPAddress: config.NodeIP,
			Port:      config.NodePort,
			Status:    NodeStatusActive,
			LastSeen:  time.Now(),
		},
		nodes:           make(map[string]*NodeInfo),
		clients:         make(map[string]*Client),
		userToClient:    make(map[string]*Client),
		agentClients:    make(map[string]*Client),
		sseClients:      make(map[string]*SSEConnection),
		register:        make(chan *Client, config.MessageBufferSize),
		unregister:      make(chan *Client, config.MessageBufferSize),
		broadcast:       make(chan *HubMessage, config.MessageBufferSize*4),
		nodeMessage:     make(chan *DistributedMessage, config.MessageBufferSize*4),
		pendingMessages: make(chan *HubMessage, 1000), // ä½¿ç”¨é»˜è®¤å€¼
		maxPendingSize:  1000,
		ackManager:      NewAckManager(config.AckTimeout, config.AckMaxRetries),
		welcomeProvider: nil, // ä½¿ç”¨é»˜è®¤æ¬¢è¿æä¾›è€…
		ctx:             ctx,
		cancel:          cancel,
		startCh:         make(chan struct{}),
		config:          config,
		logger:          initLogger(config),
		msgPool: sync.Pool{
			New: func() interface{} {
				return make([]byte, 0, 1024) // é¢„åˆ†é…1KBç¼“å†²
			},
		},
	}
	return hub
}

// Run å¯åŠ¨Hub
func (h *Hub) Run() {
	h.wg.Add(1)
	defer h.wg.Done()

	// è®°å½•Hubå¯åŠ¨æ—¥å¿—
	h.logger.InfoKV("Hubå¯åŠ¨ä¸­",
		"node_id", h.nodeID,
		"node_ip", h.config.NodeIP,
		"node_port", h.config.NodePort,
	)

	// è®¾ç½®å·²å¯åŠ¨æ ‡å¿—å¹¶é€šçŸ¥ç­‰å¾…çš„goroutine
	if h.started.CompareAndSwap(false, true) {
		h.logger.InfoKV("Hubå¯åŠ¨æˆåŠŸ",
			"node_id", h.nodeID,
			"message_buffer", h.config.MessageBufferSize,
			"heartbeat_interval", h.config.HeartbeatInterval,
		)

		// è®¾ç½®å¯åŠ¨æ—¶é—´åˆ° Redis
		if h.statsRepo != nil {
			go func() {
				ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
				defer cancel()
				_ = h.statsRepo.SetStartTime(ctx, h.nodeID, time.Now().Unix())
			}()
		}

		// å¯åŠ¨æŒ‡æ ‡æ”¶é›†å™¨ï¼ˆå¦‚æœå·²é…ç½®ï¼‰
		close(h.startCh)
	}

	ticker := time.NewTicker(time.Duration(h.config.HeartbeatInterval) * time.Second)
	defer ticker.Stop()

	// æ€§èƒ½ç›‘æ§å®šæ—¶å™¨ - æ¯5åˆ†é’ŸæŠ¥å‘Šä¸€æ¬¡
	perfTicker := time.NewTicker(5 * time.Minute)
	defer perfTicker.Stop()

	// å¯åŠ¨å¾…å‘é€æ¶ˆæ¯å¤„ç†goroutine
	go h.processPendingMessages()

	for {
		select {
		case <-h.ctx.Done():
			return
		case client := <-h.register:
			h.handleRegister(client)
		case client := <-h.unregister:
			h.handleUnregister(client)
		case message := <-h.broadcast:
			h.handleBroadcast(message)
		case <-ticker.C:
			h.checkHeartbeat()
		case <-perfTicker.C:
			h.reportPerformanceMetrics()
		}
	}
}

// reportPerformanceMetrics æŠ¥å‘Šæ€§èƒ½æŒ‡æ ‡
func (h *Hub) reportPerformanceMetrics() {
	h.mutex.RLock()
	activeClients := len(h.clients)
	sseClients := len(h.sseClients)
	h.mutex.RUnlock()

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// ä» Redis è·å–ç»Ÿè®¡ä¿¡æ¯
	if h.statsRepo == nil {
		return
	}

	stats, err := h.statsRepo.GetNodeStats(ctx, h.nodeID)
	if err != nil {
		h.logger.WarnKV("è·å–èŠ‚ç‚¹ç»Ÿè®¡å¤±è´¥", "error", err)
		return
	}

	// è®°å½•æ€§èƒ½æŒ‡æ ‡æ—¥å¿—
	h.logger.InfoKV("Hubæ€§èƒ½æŒ‡æ ‡",
		"active_websocket_clients", activeClients,
		"active_sse_clients", sseClients,
		"total_connections", stats.TotalConnections,
		"total_messages_sent", stats.MessagesSent,
		"total_broadcasts_sent", stats.BroadcastsSent,
		"node_id", h.nodeID,
		"uptime_seconds", stats.Uptime,
	)
}

// WaitForStart ç­‰å¾…Hubå¯åŠ¨å®Œæˆ
// è¿™ä¸ªæ–¹æ³•å¯¹äºç”¨æˆ·æ¥è¯´å¾ˆé‡è¦ï¼Œç¡®ä¿Hubå®Œå…¨å¯åŠ¨åå†è¿›è¡Œæ“ä½œ
func (h *Hub) WaitForStart() {
	<-h.startCh
}

// WaitForStartWithTimeout å¸¦è¶…æ—¶çš„ç­‰å¾…Hubå¯åŠ¨
func (h *Hub) WaitForStartWithTimeout(timeout time.Duration) error {
	select {
	case <-h.startCh:
		return nil
	case <-time.After(timeout):
		return errorx.NewError(ErrTypeHubStartupTimeout)
	}
}

// IsStarted æ£€æŸ¥Hubæ˜¯å¦å·²å¯åŠ¨
func (h *Hub) IsStarted() bool {
	return h.started.Load()
}

// IsShutdown æ£€æŸ¥Hubæ˜¯å¦å·²å…³é—­
func (h *Hub) IsShutdown() bool {
	return h.shutdown.Load()
}

// SafeShutdown å®‰å…¨å…³é—­Hubï¼Œç¡®ä¿æ‰€æœ‰æ“ä½œå®Œæˆ
func (h *Hub) SafeShutdown() error {
	// æ£€æŸ¥æ˜¯å¦å·²ç»å…³é—­
	if h.shutdown.Load() {
		h.logger.Debug("Hubå·²ç»å…³é—­ï¼Œè·³è¿‡é‡å¤å…³é—­æ“ä½œ")
		return nil
	}

	// å®‰å…¨è·å–å®¢æˆ·ç«¯æ•°é‡
	h.mutex.RLock()
	clientCount := len(h.clients)
	h.mutex.RUnlock()

	// è®°å½•å…³é—­å¼€å§‹æ—¥å¿—
	h.logger.InfoKV("Hubå¼€å§‹å®‰å…¨å…³é—­",
		"node_id", h.nodeID,
		"connected_clients", clientCount,
	)

	// è®¾ç½®å…³é—­æ ‡å¿—
	if !h.shutdown.CompareAndSwap(false, true) {
		return nil // å·²ç»åœ¨å…³é—­ä¸­
	}

	// å–æ¶ˆcontext
	h.cancel()

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆï¼Œå¸¦è¶…æ—¶ä¿æŠ¤
	done := make(chan struct{})
	go func() {
		h.wg.Wait()
		close(done)
	}()

	// åœ¨æµ‹è¯•ç¯å¢ƒä¸­ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
	timeout := 30 * time.Second
	if testing.Testing() {
		timeout = 5 * time.Second
	}

	select {
	case <-done:
		// æ­£å¸¸å…³é—­
		finalStats := map[string]interface{}{
			"total_connections": int64(0),
			"messages_sent":     int64(0),
			"broadcasts_sent":   int64(0),
		}

		if h.statsRepo != nil {
			ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
			stats, _ := h.statsRepo.GetNodeStats(ctx, h.nodeID)
			cancel()

			if stats != nil {
				finalStats["total_connections"] = stats.TotalConnections
				finalStats["messages_sent"] = stats.MessagesSent
				finalStats["broadcasts_sent"] = stats.BroadcastsSent
			}
		}

		h.logger.InfoKV("Hubå®‰å…¨å…³é—­æˆåŠŸ",
			"node_id", h.nodeID,
			"shutdown_timeout", timeout,
			"final_stats", finalStats,
		)
	case <-time.After(timeout):
		// å¼ºåˆ¶å…³é—­æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥
		h.logger.WarnKV("Hubå…³é—­è¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­æ‰€æœ‰è¿æ¥",
			"node_id", h.nodeID,
			"timeout", timeout,
			"remaining_clients", len(h.clients),
			"remaining_sse_clients", len(h.sseClients),
		)
		h.mutex.Lock()
		for _, client := range h.clients {
			if client.Conn != nil {
				client.Conn.Close()
			}
			select {
			case <-client.SendChan:
			default:
				close(client.SendChan)
			}
		}
		h.mutex.Unlock()
		return ErrHubShutdownTimeout
	}

	// å…³é—­æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥å’Œchannel
	h.mutex.Lock()
	for _, client := range h.clients {
		if client.Conn != nil {
			client.Conn.Close()
		}
		close(client.SendChan)
	}
	h.mutex.Unlock()

	// å…³é—­SSEè¿æ¥
	h.sseMutex.Lock()
	for _, conn := range h.sseClients {
		close(conn.CloseCh)
	}
	h.sseMutex.Unlock()

	return nil
}

// Register æ³¨å†Œå®¢æˆ·ç«¯
func (h *Hub) Register(client *Client) {
	h.logger.DebugKV("å®¢æˆ·ç«¯æ³¨å†Œè¯·æ±‚", "client_id", client.ID, "user_id", client.UserID)
	h.register <- client
}

// Unregister æ³¨é”€å®¢æˆ·ç«¯
func (h *Hub) Unregister(client *Client) {
	h.logger.DebugKV("å®¢æˆ·ç«¯æ³¨é”€è¯·æ±‚", "client_id", client.ID, "user_id", client.UserID)
	h.unregister <- client
}

// sendToUser å‘é€æ¶ˆæ¯ç»™æŒ‡å®šç”¨æˆ·ï¼ˆè‡ªåŠ¨å¡«å……å‘é€è€…ä¿¡æ¯ï¼‰- å†…éƒ¨æ–¹æ³•
func (h *Hub) sendToUser(ctx context.Context, toUserID string, msg *HubMessage) error {
	// ç›´æ¥ä¿®æ”¹åŸå§‹æ¶ˆæ¯å¯¹è±¡ï¼Œé¿å…å¼•ç”¨æ–­è£‚
	if msg.Sender == "" {
		if senderID, ok := ctx.Value(ContextKeySenderID).(string); ok {
			msg.Sender = senderID
		} else if userID, ok := ctx.Value(ContextKeyUserID).(string); ok {
			msg.Sender = userID
		}
	}

	msg.Receiver = toUserID
	if msg.CreateAt.IsZero() {
		msg.CreateAt = time.Now()
	}

	// ç¡®ä¿æ¶ˆæ¯IDå­˜åœ¨
	if msg.ID == "" {
		msg.ID = fmt.Sprintf("%s-%d", toUserID, time.Now().UnixNano())
	}

	// å°è¯•å‘é€åˆ°broadcasté˜Ÿåˆ—
	select {
	case h.broadcast <- msg:
		h.logger.DebugKV("æ¶ˆæ¯å·²å¹¿æ’­", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType)
		// è®°å½•æ¶ˆæ¯åˆ°æ•°æ®åº“
		go h.recordMessageToDatabase(msg, nil)
		return nil
	default:
		// broadcasté˜Ÿåˆ—æ»¡ï¼Œå°è¯•æ”¾å…¥å¾…å‘é€é˜Ÿåˆ—
		select {
		case h.pendingMessages <- msg:
			h.logger.DebugKV("æ¶ˆæ¯å·²æ”¾å…¥å¾…å‘é€é˜Ÿåˆ—", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType)
			// è®°å½•æ¶ˆæ¯åˆ°æ•°æ®åº“
			go h.recordMessageToDatabase(msg, nil)
			return nil
		default:
			err := ErrQueueAndPendingFull
			// è®°å½•æ¶ˆæ¯å‘é€å¤±è´¥æ—¥å¿—
			h.logger.ErrorKV("æ¶ˆæ¯å‘é€å¤±è´¥", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType, "error", err)
			// è®°å½•å¤±è´¥æ¶ˆæ¯åˆ°æ•°æ®åº“
			go h.recordMessageToDatabase(msg, err)
			// é€šçŸ¥é˜Ÿåˆ—æ»¡å¤„ç†å™¨
			h.notifyQueueFull(msg, toUserID, "all_queues", err)
			return err
		}
	}
}

// SendToUserWithRetry å¸¦é‡è¯•æœºåˆ¶çš„å‘é€æ¶ˆæ¯ç»™æŒ‡å®šç”¨æˆ·
func (h *Hub) SendToUserWithRetry(ctx context.Context, toUserID string, msg *HubMessage) *SendResult {
	result := &SendResult{
		Attempts: make([]SendAttempt, 0, h.config.MaxRetries+1),
	}

	startTime := time.Now()

	// åˆ›å»º go-toolbox retry å®ä¾‹ç”¨äºå»¶è¿Ÿè®¡ç®—å’Œæ¡ä»¶åˆ¤æ–­
	retryInstance := retry.NewRetryWithCtx(ctx).
		SetAttemptCount(h.config.MaxRetries + 1). // +1 å› ä¸ºç¬¬ä¸€æ¬¡ä¸æ˜¯é‡è¯•
		SetInterval(h.config.BaseDelay).
		SetConditionFunc(h.isRetryableError)

	// æ‰§è¡Œå¸¦è¯¦ç»†è®°å½•çš„é‡è¯•é€»è¾‘
	finalErr := retryInstance.Do(func() error {
		attemptStart := time.Now()
		attemptNumber := len(result.Attempts) + 1

		err := h.sendToUser(ctx, toUserID, msg)
		duration := time.Since(attemptStart)

		// è®°å½•æ¯æ¬¡å°è¯•
		sendAttempt := SendAttempt{
			AttemptNumber: attemptNumber,
			StartTime:     attemptStart,
			Duration:      duration,
			Error:         err,
			Success:       err == nil,
		}
		result.Attempts = append(result.Attempts, sendAttempt)

		// ğŸ”¥ å¦‚æœæ˜¯é‡è¯•ï¼ˆéé¦–æ¬¡å°è¯•ï¼‰ï¼Œè®°å½•é‡è¯•ä¿¡æ¯åˆ°æ•°æ®åº“
		if attemptNumber > 1 && h.messageRecordRepo != nil {
			retryAttempt := RetryAttempt{
				AttemptNumber: attemptNumber,
				Timestamp:     attemptStart,
				Duration:      duration,
				Error:         "",
				Success:       err == nil,
			}
			if err != nil {
				retryAttempt.Error = err.Error()
			}

			// å¼‚æ­¥æ›´æ–°æ•°æ®åº“é‡è¯•è®°å½•ï¼ˆé¿å…é˜»å¡ä¸»æµç¨‹ï¼‰
			go func() {
				if updateErr := h.messageRecordRepo.IncrementRetry(msg.ID, retryAttempt); updateErr != nil {
					h.logger.DebugKV("æ›´æ–°é‡è¯•è®°å½•å¤±è´¥",
						"message_id", msg.ID,
						"attempt", attemptNumber,
						"error", updateErr,
					)
				}
			}()
		}

		return err
	})

	// è®¾ç½®æœ€ç»ˆç»“æœ
	result.Success = finalErr == nil
	result.FinalError = finalErr
	result.TotalTime = time.Since(startTime)
	result.TotalRetries = len(result.Attempts) - 1 // å‡1å› ä¸ºç¬¬ä¸€æ¬¡ä¸ç®—é‡è¯•

	// è§¦å‘å¤±è´¥å›è°ƒï¼ˆåªæœ‰åœ¨æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åæ‰è§¦å‘ï¼‰
	if finalErr != nil {
		h.notifySendFailureAfterRetries(msg, toUserID, result)
	}

	return result
}

// isRetryableError åˆ¤æ–­é”™è¯¯æ˜¯å¦å¯ä»¥é‡è¯• - å®Œå…¨åŸºäºé”™è¯¯ç±»å‹
func (h *Hub) isRetryableError(err error) bool {
	if err == nil {
		return false
	}

	// ä½¿ç”¨errorsåŒ…è¿›è¡Œç±»å‹åˆ¤æ–­
	return IsRetryableError(err)
}

// shouldRetryBasedOnErrorPattern åŸºäºé”™è¯¯æ¨¡å¼å†³å®šæ˜¯å¦é‡è¯•ï¼ˆæ¨èä½¿ç”¨ isRetryableErrorï¼‰
func (h *Hub) shouldRetryBasedOnErrorPattern(err error) bool {
	return h.isRetryableError(err)
}

// notifySendFailureAfterRetries åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åé€šçŸ¥å¤±è´¥å¤„ç†å™¨
func (h *Hub) notifySendFailureAfterRetries(msg *HubMessage, recipient string, result *SendResult) {
	// è®°å½•é‡è¯•æœ€ç»ˆå¤±è´¥çš„æ—¥å¿—
	h.logger.ErrorKV("æ¶ˆæ¯å‘é€é‡è¯•å¤±è´¥",
		"message_id", msg.ID,
		"sender", msg.Sender,
		"receiver", recipient,
		"message_type", msg.MessageType,
		"total_retries", result.TotalRetries,
		"total_time", result.TotalTime,
		"final_error", result.FinalError,
	)

	h.failureHandlerMutex.RLock()
	handlers := make([]SendFailureHandler, len(h.sendFailureHandlers))
	copy(handlers, h.sendFailureHandlers)
	h.failureHandlerMutex.RUnlock()

	for _, handler := range handlers {
		go func(handler SendFailureHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("SendFailureHandler panic (retry exhausted)",
						"message_id", msg.ID,
						"recipient", recipient,
						"panic", r,
					)
				}
			}()
			// ä½¿ç”¨ç‰¹æ®Šçš„å¤±è´¥åŸå› è¡¨ç¤ºè¿™æ˜¯ç»è¿‡é‡è¯•åçš„å¤±è´¥
			reason := fmt.Sprintf("retry_exhausted_%d_attempts", result.TotalRetries+1)
			handler.HandleSendFailure(msg, recipient, reason, result.FinalError)
		}(handler)
	}
}

// Broadcast å¹¿æ’­æ¶ˆæ¯
func (h *Hub) Broadcast(ctx context.Context, msg *HubMessage) {
	if msg.CreateAt.IsZero() {
		msg.CreateAt = time.Now()
	}

	select {
	case h.broadcast <- msg:
		// æˆåŠŸæ”¾å…¥å¹¿æ’­é˜Ÿåˆ—
	default:
		// broadcasté˜Ÿåˆ—æ»¡ï¼Œå°è¯•æ”¾å…¥å¾…å‘é€é˜Ÿåˆ—
		h.logger.WarnKV("å¹¿æ’­é˜Ÿåˆ—å·²æ»¡ï¼Œå°è¯•ä½¿ç”¨å¾…å‘é€é˜Ÿåˆ—",
			"message_id", msg.ID,
			"sender", msg.Sender,
			"message_type", msg.MessageType,
		)
		select {
		case h.pendingMessages <- msg:
			// æˆåŠŸæ”¾å…¥å¾…å‘é€é˜Ÿåˆ—
		default:
			// ä¸¤ä¸ªé˜Ÿåˆ—éƒ½æ»¡ï¼Œé™é»˜ä¸¢å¼ƒï¼ˆå¹¿æ’­æ¶ˆæ¯ä¸è¿”å›é”™è¯¯ï¼‰
			h.logger.ErrorKV("æ‰€æœ‰é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå¹¿æ’­æ¶ˆæ¯",
				"message_id", msg.ID,
				"sender", msg.Sender,
				"message_type", msg.MessageType,
				"content_length", len(msg.Content),
			)
		}
	}
}

// processPendingMessages å¤„ç†å¾…å‘é€æ¶ˆæ¯é˜Ÿåˆ—
func (h *Hub) processPendingMessages() {
	h.wg.Add(1)
	defer h.wg.Done()

	// è®°å½•å¾…å‘é€æ¶ˆæ¯å¤„ç†å™¨å¯åŠ¨
	h.logger.InfoKV("å¾…å‘é€æ¶ˆæ¯å¤„ç†å™¨å¯åŠ¨",
		"node_id", h.nodeID,
		"check_interval", "100ms",
	)

	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	processedCount := 0
	timeoutCount := 0

	for {
		select {
		case <-h.ctx.Done():
			// è®°å½•å¤„ç†å™¨å…³é—­ç»Ÿè®¡
			h.logger.InfoKV("å¾…å‘é€æ¶ˆæ¯å¤„ç†å™¨å…³é—­",
				"processed_count", processedCount,
				"timeout_count", timeoutCount,
			)
			return
		case msg := <-h.pendingMessages:
			// å°è¯•å°†æ¶ˆæ¯æ”¾å…¥broadcasté˜Ÿåˆ—
			select {
			case h.broadcast <- msg:
				// æˆåŠŸå‘é€
				processedCount++
			case <-time.After(5 * time.Second):
				// è¶…æ—¶ï¼Œä¸¢å¼ƒæ¶ˆæ¯
				timeoutCount++
				h.logger.WarnKV("å¾…å‘é€æ¶ˆæ¯å¤„ç†è¶…æ—¶",
					"message_id", msg.ID,
					"sender", msg.Sender,
					"receiver", msg.Receiver,
					"message_type", msg.MessageType,
					"timeout", "5s",
				)
			}
		case <-ticker.C:
			// å®šæœŸæ£€æŸ¥ï¼Œé¿å…goroutineé˜»å¡
			if processedCount%100 == 0 && processedCount > 0 {
				h.logger.InfoKV("å¾…å‘é€æ¶ˆæ¯å¤„ç†è¿›åº¦",
					"processed_count", processedCount,
					"timeout_count", timeoutCount,
					"success_rate", fmt.Sprintf("%.2f%%", float64(processedCount)/float64(processedCount+timeoutCount)*100),
				)
			}
		}
	}
}

// RegisterSSE æ³¨å†ŒSSEè¿æ¥
func (h *Hub) RegisterSSE(conn *SSEConnection) {
	h.sseMutex.Lock()
	defer h.sseMutex.Unlock()
	h.sseClients[conn.UserID] = conn

	// è®°å½•SSEè¿æ¥æ³¨å†Œæ—¥å¿—
	h.logger.InfoKV("SSEè¿æ¥å»ºç«‹", "user_id", conn.UserID)
	h.logger.InfoKV("SSEè¿æ¥å·²æ³¨å†Œ",
		"user_id", conn.UserID,
		"total_sse_clients", len(h.sseClients),
	)
}

// UnregisterSSE æ³¨é”€SSEè¿æ¥
func (h *Hub) UnregisterSSE(userID string) {
	h.sseMutex.Lock()
	defer h.sseMutex.Unlock()
	if conn, exists := h.sseClients[userID]; exists {
		// è®°å½•SSEè¿æ¥æ³¨é”€æ—¥å¿—
		h.logger.InfoKV("SSEè¿æ¥æ–­å¼€", "user_id", userID)
		h.logger.InfoKV("SSEè¿æ¥å·²æ³¨é”€",
			"user_id", userID,
			"remaining_sse_clients", len(h.sseClients)-1,
		)

		close(conn.CloseCh)
		delete(h.sseClients, userID)
	}
}

// SendToUserViaSSE é€šè¿‡SSEå‘é€æ¶ˆæ¯
func (h *Hub) SendToUserViaSSE(userID string, msg *HubMessage) bool {
	h.sseMutex.RLock()
	conn, exists := h.sseClients[userID]
	h.sseMutex.RUnlock()

	if !exists {
		h.logger.WarnKV("SSEç”¨æˆ·ä¸å­˜åœ¨",
			"user_id", userID,
			"message_id", msg.ID,
			"message_type", msg.MessageType,
		)
		return false
	}

	select {
	case conn.MessageCh <- msg:
		conn.LastActive = time.Now()
		// è®°å½•SSEæ¶ˆæ¯å‘é€æˆåŠŸ
		h.logger.DebugKV("SSEæ¶ˆæ¯å‘é€", "message_id", msg.ID, "from", msg.Sender, "to", userID, "type", msg.MessageType)
		h.logger.InfoKV("SSEæ¶ˆæ¯å‘é€æˆåŠŸ",
			"user_id", userID,
			"message_id", msg.ID,
			"message_type", msg.MessageType,
		)
		return true
	default:
		// SSEæ¶ˆæ¯é˜Ÿåˆ—æ»¡
		h.logger.WarnKV("SSEæ¶ˆæ¯é˜Ÿåˆ—å·²æ»¡",
			"user_id", userID,
			"message_id", msg.ID,
			"message_type", msg.MessageType,
		)
		return false
	}
}

// SendToUserWithAck å‘é€æ¶ˆæ¯ç»™æŒ‡å®šç”¨æˆ·å¹¶ç­‰å¾…ACKç¡®è®¤
func (h *Hub) SendToUserWithAck(ctx context.Context, toUserID string, msg *HubMessage, timeout time.Duration, maxRetry int) (*AckMessage, error) {
	// æ£€æŸ¥æ˜¯å¦å¯ç”¨ACK
	enableAck := h.config.EnableAck

	if !enableAck {
		// å¦‚æœæœªå¯ç”¨ACKï¼Œç›´æ¥å‘é€
		h.logger.InfoKV("ACKæœªå¯ç”¨ï¼Œä½¿ç”¨é‡è¯•å‘é€",
			"message_id", msg.ID,
			"to_user", toUserID,
		)
		result := h.SendToUserWithRetry(ctx, toUserID, msg)
		return nil, result.FinalError
	}

	// ç”Ÿæˆæ¶ˆæ¯ID
	if msg.ID == "" {
		msg.ID = fmt.Sprintf("%s-%d", toUserID, time.Now().UnixNano())
	}
	msg.RequireAck = true

	// è®°å½•ACKå‘é€å¼€å§‹
	h.logger.InfoKV("ACKæ¶ˆæ¯å‘é€å¼€å§‹",
		"message_id", msg.ID,
		"to_user", toUserID,
		"timeout", timeout,
		"max_retry", maxRetry,
		"require_ack", true,
		"enable_ack", enableAck,
	)

	// æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨çº¿
	h.mutex.RLock()
	_, isOnline := h.userToClient[toUserID]
	h.mutex.RUnlock()

	if !isOnline {
		// ç”¨æˆ·ç¦»çº¿ï¼Œä½¿ç”¨ç¦»çº¿å¤„ç†å™¨å¤„ç†æ¶ˆæ¯
		if h.ackManager.offlineHandler != nil {
			if err := h.ackManager.offlineHandler.HandleOfflineMessage(msg); err != nil {
				return &AckMessage{
					MessageID: msg.ID,
					Status:    AckStatusFailed,
					Timestamp: time.Now(),
					Error:     fmt.Sprintf("ç”¨æˆ·ç¦»çº¿ä¸”ç¦»çº¿æ¶ˆæ¯å¤„ç†å¤±è´¥: %v", err),
				}, err
			}

			// ç¦»çº¿æ¶ˆæ¯å¤„ç†æˆåŠŸ
			return &AckMessage{
				MessageID: msg.ID,
				Status:    AckStatusConfirmed,
				Timestamp: time.Now(),
				Error:     "ç”¨æˆ·ç¦»çº¿ï¼Œæ¶ˆæ¯å·²å­˜å‚¨",
			}, nil
		}

		err := errorx.NewError(ErrTypeUserOffline)
		// é€šçŸ¥ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
		h.notifyUserOffline(msg, toUserID, err)

		return &AckMessage{
			MessageID: msg.ID,
			Status:    AckStatusFailed,
			Timestamp: time.Now(),
			Error:     "ç”¨æˆ·ç¦»çº¿ä¸”æœªé…ç½®ç¦»çº¿æ¶ˆæ¯å¤„ç†å™¨",
		}, err
	}

	// ä½¿ç”¨é…ç½®ä¸­çš„ACKè¶…æ—¶æ—¶é—´ï¼Œå¦‚æœä¼ å…¥çš„timeout > 0åˆ™ä½¿ç”¨ä¼ å…¥å€¼
	ackTimeout := h.config.AckTimeout
	if timeout > 0 {
		ackTimeout = timeout
	}

	// æ·»åŠ åˆ°å¾…ç¡®è®¤é˜Ÿåˆ—
	pm := h.ackManager.AddPendingMessage(msg, ackTimeout, maxRetry)
	defer h.ackManager.RemovePendingMessage(msg.ID)

	// å®šä¹‰é‡è¯•å‡½æ•°
	attemptNum := 0
	retryFunc := func() error {
		attemptNum++
		// ACK é‡è¯•åªè´Ÿè´£ç­‰å¾…ç¡®è®¤è¶…æ—¶åé‡å‘ï¼Œä¸éœ€è¦åµŒå¥—é‡è¯•
		// It looks like the code snippet is written in Go and contains an error variable declaration "err".
		// The comment "// Go" indicates that the code is written in the Go programming language. The "
		err := h.sendToUser(ctx, toUserID, msg)

		// ğŸ”¥ å¦‚æœæ˜¯é‡è¯•ï¼ˆéé¦–æ¬¡å°è¯•ï¼‰ï¼Œè®°å½•é‡è¯•ä¿¡æ¯åˆ°æ•°æ®åº“
		if attemptNum > 1 && h.messageRecordRepo != nil {
			retryAttempt := RetryAttempt{
				AttemptNumber: attemptNum,
				Timestamp:     time.Now(),
				Duration:      0, // ACKé‡è¯•çš„æŒç»­æ—¶é—´åœ¨è¿™é‡Œæ— æ³•å‡†ç¡®è®¡ç®—
				Error:         err.Error(),
				Success:       err == nil,
			}
			if err != nil {
				retryAttempt.Error = err.Error()
			}

			// å¼‚æ­¥æ›´æ–°æ•°æ®åº“é‡è¯•è®°å½•ï¼ˆé¿å…é˜»å¡ä¸»æµç¨‹ï¼‰
			go func() {
				if updateErr := h.messageRecordRepo.IncrementRetry(msg.ID, retryAttempt); updateErr != nil {
					h.logger.DebugKV("æ›´æ–°ACKé‡è¯•è®°å½•å¤±è´¥",
						"message_id", msg.ID,
						"attempt", attemptNum,
						"error", updateErr,
					)
				}
			}()
		}

		return err
	}

	// é¦–æ¬¡å‘é€
	if err := retryFunc(); err != nil {
		return &AckMessage{
			MessageID: msg.ID,
			Status:    AckStatusFailed,
			Timestamp: time.Now(),
			Error:     err.Error(),
		}, err
	}

	// ç­‰å¾…ACKç¡®è®¤å¹¶æ”¯æŒé‡è¯•
	ackMsg, err := pm.WaitForAckWithRetry(retryFunc)

	return ackMsg, err
}

// SetOfflineMessageHandler è®¾ç½®ç¦»çº¿æ¶ˆæ¯å¤„ç†å™¨
func (h *Hub) SetOfflineMessageHandler(handler OfflineMessageHandler) {
	if h.ackManager != nil {
		h.ackManager.offlineHandler = handler
	}
}

// SetOnlineStatusRepository è®¾ç½®åœ¨çº¿çŠ¶æ€ä»“åº“ï¼ˆRedisï¼‰
func (h *Hub) SetOnlineStatusRepository(repo OnlineStatusRepository) {
	h.onlineStatusRepo = repo
	h.logger.InfoKV("åœ¨çº¿çŠ¶æ€ä»“åº“å·²è®¾ç½®", "repository_type", "redis")
}

// SetWorkloadRepository è®¾ç½®è´Ÿè½½ç®¡ç†ä»“åº“ï¼ˆRedisï¼‰
func (h *Hub) SetWorkloadRepository(repo WorkloadRepository) {
	h.workloadRepo = repo
	h.logger.InfoKV("è´Ÿè½½ç®¡ç†ä»“åº“å·²è®¾ç½®", "repository_type", "redis")
}

// SetMessageRecordRepository è®¾ç½®æ¶ˆæ¯è®°å½•ä»“åº“ï¼ˆMySQLï¼‰
func (h *Hub) SetMessageRecordRepository(repo MessageRecordRepository) {
	h.messageRecordRepo = repo
	h.logger.InfoKV("æ¶ˆæ¯è®°å½•ä»“åº“å·²è®¾ç½®", "repository_type", "mysql")
}

// SetHubStatsRepository è®¾ç½® Hub ç»Ÿè®¡ä»“åº“ï¼ˆRedisï¼‰
func (h *Hub) SetHubStatsRepository(repo HubStatsRepository) {
	h.statsRepo = repo
	h.logger.InfoKV("Hubç»Ÿè®¡ä»“åº“å·²è®¾ç½®", "repository_type", "redis")

	// è®¾ç½®å¯åŠ¨æ—¶é—´åˆ° Redis
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()
	_ = repo.SetStartTime(ctx, h.nodeID, time.Now().Unix())
}

// AddSendFailureHandler æ·»åŠ é€šç”¨æ¶ˆæ¯å‘é€å¤±è´¥å¤„ç†å™¨
func (h *Hub) AddSendFailureHandler(handler SendFailureHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	h.sendFailureHandlers = append(h.sendFailureHandlers, handler)
}

// AddQueueFullHandler æ·»åŠ é˜Ÿåˆ—æ»¡å¤„ç†å™¨
func (h *Hub) AddQueueFullHandler(handler QueueFullHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	h.queueFullHandlers = append(h.queueFullHandlers, handler)
}

// AddUserOfflineHandler æ·»åŠ ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
func (h *Hub) AddUserOfflineHandler(handler UserOfflineHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	h.userOfflineHandlers = append(h.userOfflineHandlers, handler)
}

// AddConnectionErrorHandler æ·»åŠ è¿æ¥é”™è¯¯å¤„ç†å™¨
func (h *Hub) AddConnectionErrorHandler(handler ConnectionErrorHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	h.connectionErrorHandlers = append(h.connectionErrorHandlers, handler)
}

// AddTimeoutHandler æ·»åŠ è¶…æ—¶å¤„ç†å™¨
func (h *Hub) AddTimeoutHandler(handler TimeoutHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	h.timeoutHandlers = append(h.timeoutHandlers, handler)
}

// RemoveSendFailureHandler ç§»é™¤æ¶ˆæ¯å‘é€å¤±è´¥å¤„ç†å™¨
func (h *Hub) RemoveSendFailureHandler(handler SendFailureHandler) {
	h.failureHandlerMutex.Lock()
	defer h.failureHandlerMutex.Unlock()
	for i, existingHandler := range h.sendFailureHandlers {
		if existingHandler == handler {
			h.sendFailureHandlers = append(h.sendFailureHandlers[:i], h.sendFailureHandlers[i+1:]...)
			break
		}
	}
}

// notifySendFailure é€šçŸ¥æ‰€æœ‰æ³¨å†Œçš„å‘é€å¤±è´¥å¤„ç†å™¨
func (h *Hub) notifySendFailure(msg *HubMessage, recipient string, reason string, err error) {
	// è®°å½•å‘é€å¤±è´¥é€šçŸ¥
	h.logger.ErrorKV("è§¦å‘å‘é€å¤±è´¥å¤„ç†å™¨",
		"message_id", msg.ID,
		"recipient", recipient,
		"reason", reason,
		"error", err,
		"handler_count", len(h.sendFailureHandlers),
	)

	h.failureHandlerMutex.RLock()
	handlers := make([]SendFailureHandler, len(h.sendFailureHandlers))
	copy(handlers, h.sendFailureHandlers)
	h.failureHandlerMutex.RUnlock()

	for _, handler := range handlers {
		go func(handler SendFailureHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("SendFailureHandler panic",
						"message_id", msg.ID,
						"recipient", recipient,
						"reason", reason,
						"panic", r,
					)
				}
			}()
			handler.HandleSendFailure(msg, recipient, reason, err)
		}(handler)
	}
}

// notifyQueueFull é€šçŸ¥é˜Ÿåˆ—æ»¡å¤„ç†å™¨
func (h *Hub) notifyQueueFull(msg *HubMessage, recipient string, queueType string, err error) {
	// è®°å½•é˜Ÿåˆ—æ»¡é€šçŸ¥
	h.logger.WarnKV("è§¦å‘é˜Ÿåˆ—æ»¡å¤„ç†å™¨",
		"message_id", msg.ID,
		"recipient", recipient,
		"queue_type", queueType,
		"error", err,
		"queue_handlers", len(h.queueFullHandlers),
		"general_handlers", len(h.sendFailureHandlers),
	)

	h.failureHandlerMutex.RLock()
	queueHandlers := make([]QueueFullHandler, len(h.queueFullHandlers))
	copy(queueHandlers, h.queueFullHandlers)
	generalHandlers := make([]SendFailureHandler, len(h.sendFailureHandlers))
	copy(generalHandlers, h.sendFailureHandlers)
	h.failureHandlerMutex.RUnlock()

	// è°ƒç”¨ä¸“é—¨çš„é˜Ÿåˆ—æ»¡å¤„ç†å™¨
	for _, handler := range queueHandlers {
		go func(handler QueueFullHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("QueueFullHandler panic",
						"message_id", msg.ID,
						"recipient", recipient,
						"queue_type", queueType,
						"panic", r,
					)
				}
			}()
			handler.HandleQueueFull(msg, recipient, queueType, err)
		}(handler)
	}

	// åŒæ—¶è°ƒç”¨é€šç”¨å¤„ç†å™¨
	for _, handler := range generalHandlers {
		go func(handler SendFailureHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("SendFailureHandler panic (queue full)",
						"message_id", msg.ID,
						"recipient", recipient,
						"panic", r,
					)
				}
			}()
			handler.HandleSendFailure(msg, recipient, SendFailureReasonQueueFull, err)
		}(handler)
	}
}

// notifyUserOffline é€šçŸ¥ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
func (h *Hub) notifyUserOffline(msg *HubMessage, userID string, err error) {
	h.failureHandlerMutex.RLock()
	offlineHandlers := make([]UserOfflineHandler, len(h.userOfflineHandlers))
	copy(offlineHandlers, h.userOfflineHandlers)
	generalHandlers := make([]SendFailureHandler, len(h.sendFailureHandlers))
	copy(generalHandlers, h.sendFailureHandlers)
	h.failureHandlerMutex.RUnlock()

	// è°ƒç”¨ä¸“é—¨çš„ç”¨æˆ·ç¦»çº¿å¤„ç†å™¨
	for _, handler := range offlineHandlers {
		go func(handler UserOfflineHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("UserOfflineHandler panic",
						"message_id", msg.ID,
						"user_id", userID,
						"panic", r,
					)
				}
			}()
			handler.HandleUserOffline(msg, userID, err)
		}(handler)
	}

	// åŒæ—¶è°ƒç”¨é€šç”¨å¤„ç†å™¨
	for _, handler := range generalHandlers {
		go func(handler SendFailureHandler) {
			defer func() {
				if r := recover(); r != nil {
					h.logger.ErrorKV("SendFailureHandler panic (user offline)",
						"message_id", msg.ID,
						"user_id", userID,
						"panic", r,
					)
				}
			}()
			handler.HandleSendFailure(msg, userID, SendFailureReasonUserOffline, err)
		}(handler)
	}
}

// SetMessageExpireDuration è®¾ç½®æ¶ˆæ¯è¿‡æœŸæ—¶é—´
func (h *Hub) SetMessageExpireDuration(duration time.Duration) {
	if h.ackManager != nil {
		h.ackManager.expireDuration = duration
	}
}

// HandleAck å¤„ç†ACKç¡®è®¤æ¶ˆæ¯
func (h *Hub) HandleAck(ackMsg *AckMessage) {
	// è®°å½•ACKæ¶ˆæ¯å¤„ç†
	h.logger.InfoKV("æ”¶åˆ°ACKç¡®è®¤",
		"message_id", ackMsg.MessageID,
		"status", ackMsg.Status,
		"timestamp", ackMsg.Timestamp,
	)

	h.ackManager.ConfirmMessage(ackMsg.MessageID, ackMsg)
}

// GetOnlineUsers è·å–åœ¨çº¿ç”¨æˆ·
func (h *Hub) GetOnlineUsers() []string {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	users := make(map[string]bool)
	for userID := range h.userToClient {
		users[userID] = true
	}

	h.sseMutex.RLock()
	for userID := range h.sseClients {
		users[userID] = true
	}
	h.sseMutex.RUnlock()

	result := make([]string, 0, len(users))
	for userID := range users {
		result = append(result, userID)
	}
	return result
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (h *Hub) GetStats() *HubStats {
	h.mutex.RLock()
	wsCount := len(h.clients)
	agentCount := len(h.agentClients)
	h.mutex.RUnlock()

	h.sseMutex.RLock()
	sseCount := len(h.sseClients)
	h.sseMutex.RUnlock()

	stats := &HubStats{
		TotalClients:     wsCount + sseCount,
		WebSocketClients: wsCount,
		SSEClients:       sseCount,
		AgentConnections: agentCount,
		QueuedMessages:   len(h.pendingMessages),
		OnlineUsers:      h.GetOnlineUsersCount(),
		Uptime:           h.GetUptime(),
	}

	// ä» statsRepo è·å–æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if h.statsRepo != nil {
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
		defer cancel()
		if nodeStats, err := h.statsRepo.GetNodeStats(ctx, h.nodeID); err == nil && nodeStats != nil {
			stats.MessagesSent = nodeStats.MessagesSent
			stats.MessagesReceived = nodeStats.MessagesReceived
			stats.BroadcastsSent = nodeStats.BroadcastsSent
		}
	}

	return stats
}

// GetNodeID è·å–èŠ‚ç‚¹ID
func (h *Hub) GetNodeID() string {
	return h.nodeID
}

// Shutdown å…³é—­Hubï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func (h *Hub) Shutdown() {
	_ = h.SafeShutdown() // å¿½ç•¥é”™è¯¯ï¼Œä¿æŒåŸæœ‰è¡Œä¸º
}

// === å†…éƒ¨æ–¹æ³• ===

func (h *Hub) handleRegister(client *Client) {
	defer func() {
		if r := recover(); r != nil {
			h.logger.ErrorKV("handleRegister panic",
				"client_id", client.ID,
				"user_id", client.UserID,
				"panic", r,
			)
		}
	}()

	h.mutex.Lock()
	defer h.mutex.Unlock()

	// å…³é—­æ—§è¿æ¥
	if existingClient, exists := h.userToClient[client.UserID]; exists {
		h.logger.InfoKV("æ–­å¼€æ—§è¿æ¥", "client_id", existingClient.ID, "user_id", existingClient.UserID)
		if existingClient.Conn != nil {
			existingClient.Conn.Close()
		}
		h.removeClientUnsafe(existingClient)
	}

	// æ·»åŠ æ–°å®¢æˆ·ç«¯
	h.clients[client.ID] = client
	h.userToClient[client.UserID] = client

	// åˆå§‹åŒ–å¿ƒè·³æ—¶é—´
	now := time.Now()
	if client.LastHeartbeat.IsZero() {
		client.LastHeartbeat = now
	}
	if client.LastSeen.IsZero() {
		client.LastSeen = now
	}

	if client.UserType == UserTypeAgent || client.UserType == UserTypeBot {
		h.agentClients[client.UserID] = client
	}

	// ä½¿ç”¨atomicæ— é”æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
	// åŒæ­¥ç»Ÿè®¡åˆ° Redis
	if h.statsRepo != nil {
		go func() {
			ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
			defer cancel()
			_ = h.statsRepo.IncrementTotalConnections(ctx, h.nodeID, 1)
			_ = h.statsRepo.SetActiveConnections(ctx, h.nodeID, int64(len(h.clients)))
			_ = h.statsRepo.UpdateNodeHeartbeat(ctx, h.nodeID)
		}()
	}

	// è®°å½•æˆåŠŸæ³¨å†Œæ—¥å¿—
	h.logger.InfoKV("å®¢æˆ·ç«¯å·²è¿æ¥", "client_id", client.ID, "user_id", client.UserID, "user_type", client.UserType)
	h.logger.InfoKV("å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ",
		"client_id", client.ID,
		"user_id", client.UserID,
		"user_type", client.UserType,
		"active_connections", len(h.clients),
	)

	// åŒæ­¥åœ¨çº¿çŠ¶æ€åˆ° Redis
	go func() {
		ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
		defer cancel()

		onlineInfo := &OnlineClientInfo{
			ClientID:      client.ID,
			UserID:        client.UserID,
			UserType:      client.UserType,
			NodeID:        h.nodeID,
			NodeIP:        h.config.NodeIP,
			ClientIP:      client.ClientIP,
			ConnectTime:   time.Now(),
			LastSeen:      client.LastSeen,
			LastHeartbeat: client.LastHeartbeat,
			ClientType:    client.ClientType,
			Status:        client.Status,
			Metadata:      client.Metadata,
		}

		if h.onlineStatusRepo != nil {
			if err := h.onlineStatusRepo.SetOnline(ctx, client.UserID, onlineInfo, 0); err != nil {
				h.logger.ErrorKV("åŒæ­¥åœ¨çº¿çŠ¶æ€åˆ°Rediså¤±è´¥",
					"user_id", client.UserID,
					"error", err,
				)
			}
		}
	}()

	// å‘é€æ¬¢è¿æ¶ˆæ¯
	h.sendWelcomeMessage(client)

	// å¯åŠ¨å®¢æˆ·ç«¯è¯»å†™åç¨‹ï¼ˆåªæœ‰çœŸå®è¿æ¥æ‰éœ€è¦ï¼‰
	if client.Conn != nil {
		go h.handleClientWrite(client)
	}
}

func (h *Hub) handleUnregister(client *Client) {
	h.mutex.Lock()
	defer h.mutex.Unlock()
	h.removeClientUnsafe(client)
}

func (h *Hub) removeClientUnsafe(client *Client) {
	if _, exists := h.clients[client.ID]; !exists {
		return
	}

	// è®°å½•å®¢æˆ·ç«¯ç§»é™¤æ—¥å¿—
	h.logger.InfoKV("å®¢æˆ·ç«¯å·²æ–­å¼€", "client_id", client.ID, "user_id", client.UserID)
	h.logger.InfoKV("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥",
		"client_id", client.ID,
		"user_id", client.UserID,
		"user_type", client.UserType,
		"remaining_connections", len(h.clients)-1,
	)

	delete(h.clients, client.ID)
	delete(h.userToClient, client.UserID)

	if client.UserType == UserTypeAgent || client.UserType == UserTypeBot {
		delete(h.agentClients, client.UserID)
	}

	// åŒæ­¥æ´»è·ƒè¿æ¥æ•°åˆ° Redis
	if h.statsRepo != nil {
		go func() {
			ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
			defer cancel()
			_ = h.statsRepo.SetActiveConnections(ctx, h.nodeID, int64(len(h.clients)))
		}()
	}

	// ä» Redis ç§»é™¤åœ¨çº¿çŠ¶æ€
	if h.onlineStatusRepo != nil {
		go func() {
			ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
			defer cancel()

			if err := h.onlineStatusRepo.SetOffline(ctx, client.UserID); err != nil {
				h.logger.ErrorKV("ä»Redisç§»é™¤åœ¨çº¿çŠ¶æ€å¤±è´¥",
					"user_id", client.UserID,
					"error", err,
				)
			}
		}()
	}

	// å¦‚æœæ˜¯å®¢æœç¦»çº¿ï¼Œä»è´Ÿè½½ç®¡ç†ä¸­ç§»é™¤
	if (client.UserType == UserTypeAgent || client.UserType == UserTypeBot) && h.workloadRepo != nil {
		go func() {
			ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
			defer cancel()

			if err := h.workloadRepo.RemoveAgentWorkload(ctx, client.UserID); err != nil {
				h.logger.ErrorKV("ä»è´Ÿè½½ç®¡ç†ç§»é™¤å®¢æœå¤±è´¥",
					"user_id", client.UserID,
					"error", err,
				)
			} else {
				h.logger.InfoKV("å·²ä»è´Ÿè½½ç®¡ç†ç§»é™¤å®¢æœ", "user_id", client.UserID)
			}
		}()
	}

	if client.SendChan != nil {
		defer func() {
			if r := recover(); r != nil {
				h.logger.ErrorKV("å…³é—­SendChanæ—¶panic",
					"client_id", client.ID,
					"user_id", client.UserID,
					"panic", r,
				)
			}
		}()
		close(client.SendChan)
	}
}

func (h *Hub) handleBroadcast(msg *HubMessage) {
	switch {
	case msg.Receiver != "": // ç‚¹å¯¹ç‚¹æ¶ˆæ¯ - æœ€å¿«è·¯å¾„
		h.mutex.RLock()
		client := h.userToClient[msg.Receiver]
		h.mutex.RUnlock()

		if client != nil {
			h.sendToClient(client, msg)
			h.logger.DebugKV("æ¶ˆæ¯å·²å‘é€", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType)
		} else {
			// å®¢æˆ·ç«¯ä¸åœ¨çº¿ï¼Œå°è¯•SSE
			sent := h.SendToUserViaSSE(msg.Receiver, msg)
			if sent {
				h.logger.DebugKV("æ¶ˆæ¯å·²å‘é€", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType)
			} else {
				// SSEä¹Ÿå¤±è´¥ï¼Œè®°å½•ç”¨æˆ·ç¦»çº¿
				h.logger.WarnKV("ç”¨æˆ·ç¦»çº¿", "message_id", msg.ID, "from", msg.Sender, "to", msg.Receiver, "type", msg.MessageType)
				h.logger.WarnKV("ç”¨æˆ·ç¦»çº¿ï¼Œæ¶ˆæ¯å‘é€å¤±è´¥",
					"message_id", msg.ID,
					"sender", msg.Sender,
					"receiver", msg.Receiver,
					"message_type", msg.MessageType,
				)
			}
		}

	default: // å¹¿æ’­æ¶ˆæ¯
		// ç»Ÿè®¡å¹¿æ’­æ•°åˆ° Redis
		if h.statsRepo != nil {
			go func() {
				ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
				defer cancel()
				_ = h.statsRepo.IncrementBroadcastsSent(ctx, h.nodeID, 1)
			}()
		}

		// è®°å½•å¹¿æ’­æ¶ˆæ¯æ—¥å¿—
		h.logger.InfoKV("å‘é€å¹¿æ’­æ¶ˆæ¯",
			"message_id", msg.ID,
			"sender", msg.Sender,
			"message_type", msg.MessageType,
			"content_length", len(msg.Content),
			"target_clients", len(h.clients),
		)

		// å¤åˆ¶å®¢æˆ·ç«¯åˆ—è¡¨ä»¥é¿å…åœ¨éå†æ—¶æŒæœ‰é”
		h.mutex.RLock()
		clients := make([]*Client, 0, len(h.clients))
		for _, client := range h.clients {
			clients = append(clients, client)
		}
		h.mutex.RUnlock()

		// åœ¨é‡Šæ”¾é”åå‘é€æ¶ˆæ¯
		for _, client := range clients {
			h.sendToClient(client, msg)
		}

		h.sseMutex.RLock()
		for _, conn := range h.sseClients {
			select {
			case conn.MessageCh <- msg:
			default:
			}
		}
		h.sseMutex.RUnlock()
	}
}

// fastMarshalMessage é«˜æ•ˆæ¶ˆæ¯åºåˆ—åŒ–æ–¹æ³•ï¼ŒåŒ…å«å®Œæ•´çš„HubMessageç»“æ„ä½“å­—æ®µ
func (h *Hub) fastMarshalMessage(msg *HubMessage, buf []byte) ([]byte, error) {
	// ä½¿ç”¨æ ‡å‡† json.Marshal ç¡®ä¿æ­£ç¡®çš„JSONæ ¼å¼
	// è™½ç„¶æ€§èƒ½ç¨ä½ï¼Œä½†ç¡®ä¿äº†æ•°æ®æ ¼å¼çš„æ­£ç¡®æ€§å’Œå…¼å®¹æ€§
	return json.Marshal(msg)
}

func (h *Hub) sendToClient(client *Client, msg *HubMessage) {
	defer func() {
		if r := recover(); r != nil {
			h.logger.ErrorKV("sendToClient panic",
				"client_id", client.ID,
				"user_id", client.UserID,
				"message_id", msg.ID,
				"message_type", msg.MessageType,
				"panic", r,
			)
		}
	}()

	// æ£€æŸ¥Hubæ˜¯å¦å·²å…³é—­
	if h.shutdown.Load() {
		return
	}

	// ä½¿ç”¨å¯¹è±¡æ± è·å–å­—èŠ‚ç¼“å†²
	buf := h.msgPool.Get().([]byte)
	buf = buf[:0] // é‡ç½®é•¿åº¦ï¼Œä¿ç•™å®¹é‡
	defer h.msgPool.Put(buf)

	// é«˜æ•ˆåºåˆ—åŒ– - é¿å…åå°„å’Œå†…å­˜åˆ†é…
	data, err := h.fastMarshalMessage(msg, buf)
	if err != nil {
		h.logger.ErrorKV("æ¶ˆæ¯åºåˆ—åŒ–å¤±è´¥",
			"message_id", msg.ID,
			"client_id", client.ID,
			"user_id", client.UserID,
			"error", err,
		)

		return
	}
	// å†æ¬¡æ£€æŸ¥ï¼Œé¿å…åœ¨åºåˆ—åŒ–è¿‡ç¨‹ä¸­ shutdown
	if h.shutdown.Load() {
		return
	}

	select {
	case client.SendChan <- data:
		// åŒæ­¥åˆ° Redis
		if h.statsRepo != nil {
			go func() {
				ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
				defer cancel()
				_ = h.statsRepo.IncrementMessagesSent(ctx, h.nodeID, 1)
			}()
		}

		// æ›´æ–°æŒ‡æ ‡æ”¶é›†å™¨
	case <-h.ctx.Done():
		return
	default:
		// é˜Ÿåˆ—æ»¡ï¼Œè·³è¿‡è¯¥æ¶ˆæ¯
		h.logger.WarnKV("å®¢æˆ·ç«¯å‘é€é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æ¶ˆæ¯",
			"client_id", client.ID,
			"user_id", client.UserID,
			"message_id", msg.ID,
			"message_type", msg.MessageType,
		)

	}
}

func (h *Hub) handleClientWrite(client *Client) {
	h.wg.Add(1)
	defer h.wg.Done()
	defer func() {
		// è®°å½•å®¢æˆ·ç«¯å†™å…¥åç¨‹ç»“æŸ
		h.logger.InfoKV("å®¢æˆ·ç«¯å†™å…¥åç¨‹ç»“æŸ",
			"client_id", client.ID,
			"user_id", client.UserID,
		)
		if client.Conn != nil {
			client.Conn.Close()
		}
		h.Unregister(client)
	}()

	// è®°å½•å®¢æˆ·ç«¯å†™å…¥åç¨‹å¯åŠ¨
	h.logger.InfoKV("å®¢æˆ·ç«¯å†™å…¥åç¨‹å¯åŠ¨",
		"client_id", client.ID,
		"user_id", client.UserID,
		"user_type", client.UserType,
	)

	messagesSent := 0
	messagesFailed := 0

	for {
		select {
		case message, ok := <-client.SendChan:
			if !ok {
				h.logger.InfoKV("å®¢æˆ·ç«¯å‘é€é€šé“å…³é—­",
					"client_id", client.ID,
					"user_id", client.UserID,
					"messages_sent", messagesSent,
					"messages_failed", messagesFailed,
				)
				return
			}

			if client.Conn != nil {
				client.Conn.SetWriteDeadline(time.Now().Add(10 * time.Second))
				if err := client.Conn.WriteMessage(websocket.TextMessage, message); err != nil {
					// è®°å½•å†™å…¥å¤±è´¥
					messagesFailed++
					h.logger.ErrorKV("å®¢æˆ·ç«¯æ¶ˆæ¯å†™å…¥å¤±è´¥",
						"client_id", client.ID,
						"user_id", client.UserID,
						"error", err,
						"message_size", len(message),
					)

					// æ›´æ–°æ¶ˆæ¯å‘é€çŠ¶æ€ä¸ºå¤±è´¥
					h.updateMessageSendStatus(message, MessageSendStatusFailed, FailureReasonNetworkError, err.Error())
					return
				}
				messagesSent++

				// ğŸ”¥ æ›´æ–°æ¶ˆæ¯å‘é€çŠ¶æ€ä¸ºæˆåŠŸ
				h.updateMessageSendStatus(message, MessageSendStatusSuccess, "", "")
			}
		case <-h.ctx.Done():
			h.logger.InfoKV("å®¢æˆ·ç«¯å†™å…¥åç¨‹å› Hubå…³é—­è€Œç»“æŸ",
				"client_id", client.ID,
				"user_id", client.UserID,
				"messages_sent", messagesSent,
				"messages_failed", messagesFailed,
			)
			return
		}
	}
}

func (h *Hub) checkHeartbeat() {
	h.mutex.Lock()
	defer h.mutex.Unlock()

	now := time.Now()
	timeoutClients := 0
	timeoutSSE := 0

	// ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤90ç§’
	timeoutDuration := h.heartbeatTimeout
	if timeoutDuration == 0 {
		timeoutDuration = time.Duration(h.config.ClientTimeout) * time.Second
	}

	for _, client := range h.clients {
		// ä¼˜å…ˆä½¿ç”¨LastHeartbeatï¼Œå¦‚æœä¸ºé›¶åˆ™ä½¿ç”¨LastSeen
		lastActive := client.LastHeartbeat
		if lastActive.IsZero() {
			lastActive = client.LastSeen
		}

		if now.Sub(lastActive) > timeoutDuration {
			h.logger.WarnKV("å¿ƒè·³è¶…æ—¶", "client_id", client.ID, "user_id", client.UserID, "last_heartbeat", client.LastHeartbeat)

			// è°ƒç”¨å¿ƒè·³è¶…æ—¶å›è°ƒå‡½æ•°
			if h.heartbeatTimeoutHandler != nil {
				h.heartbeatTimeoutHandler(client.ID, client.UserID, lastActive)
			}

			// å…³é—­è¿æ¥
			if client.Conn != nil {
				client.Conn.Close()
			}
			h.removeClientUnsafe(client)
			timeoutClients++
		}
	}

	// æ£€æŸ¥SSEè¶…æ—¶
	h.sseMutex.Lock()
	for userID, conn := range h.sseClients {
		if now.Sub(conn.LastActive) > time.Duration(h.config.SSETimeout)*time.Second {
			h.logger.WarnKV("SSEè¿æ¥è¶…æ—¶", "user_id", userID, "last_heartbeat", conn.LastActive)
			close(conn.CloseCh)
			delete(h.sseClients, userID)
			timeoutSSE++
		}
	}
	h.sseMutex.Unlock()

	// è®°å½•å¿ƒè·³æ£€æŸ¥ç»Ÿè®¡
	if timeoutClients > 0 || timeoutSSE > 0 {
		h.logger.InfoKV("å¿ƒè·³æ£€æŸ¥å®Œæˆ",
			"timeout_clients", timeoutClients,
			"timeout_sse", timeoutSSE,
			"remaining_clients", len(h.clients),
			"remaining_sse", len(h.sseClients),
		)
	}
}

// SetWelcomeProvider è®¾ç½®æ¬¢è¿æ¶ˆæ¯æä¾›è€…
func (h *Hub) SetWelcomeProvider(provider WelcomeMessageProvider) {
	h.welcomeProvider = provider
}

// SetRateLimiter è®¾ç½®æ¶ˆæ¯é¢‘ç‡é™åˆ¶å™¨
func (h *Hub) SetRateLimiter(limiter *RateLimiter) {
	h.rateLimiter = limiter
}

// SetPoolManager è®¾ç½®è¿æ¥æ± ç®¡ç†å™¨
func (h *Hub) SetPoolManager(manager PoolManager) {
	h.poolManager = manager
}

// GetPoolManager è·å–è¿æ¥æ± ç®¡ç†å™¨
func (h *Hub) GetPoolManager() PoolManager {
	return h.poolManager
}

// GetSMTPClient ä»è¿æ¥æ± ç®¡ç†å™¨è·å–SMTPå®¢æˆ·ç«¯
func (h *Hub) GetSMTPClient() interface{} {
	if h.poolManager != nil {
		return h.poolManager.GetSMTPClient()
	}
	return nil
}

// GetRateLimiter è·å–æ¶ˆæ¯é¢‘ç‡é™åˆ¶å™¨
func (h *Hub) GetRateLimiter() *RateLimiter {
	return h.rateLimiter
}

// SetHeartbeatConfig è®¾ç½®å¿ƒè·³é…ç½®
// interval: å¿ƒè·³é—´éš”ï¼Œå»ºè®®30ç§’
// timeout: å¿ƒè·³è¶…æ—¶æ—¶é—´ï¼Œå»ºè®®90ç§’ï¼ˆintervalçš„3å€ï¼‰
func (h *Hub) SetHeartbeatConfig(interval, timeout time.Duration) {
	h.heartbeatInterval = interval
	h.heartbeatTimeout = timeout
}

// UpdateHeartbeat æ›´æ–°å®¢æˆ·ç«¯å¿ƒè·³æ—¶é—´
func (h *Hub) UpdateHeartbeat(clientID string) {
	h.mutex.Lock()
	defer h.mutex.Unlock()

	if client, exists := h.clients[clientID]; exists {
		now := time.Now()
		client.LastHeartbeat = now
		client.LastSeen = now
	}
}

func (h *Hub) sendWelcomeMessage(client *Client) {
	provider := h.welcomeProvider

	if provider == nil {
		return
	}

	extraData := map[string]interface{}{
		"client_id": client.ID,
		"node_id":   h.nodeID,
		"time":      time.Now().Format("2006-01-02 15:04:05"),
	}

	welcomeMsg, enabled, err := provider.GetWelcomeMessage(
		client.UserID,
		client.Role,
		client.UserType,
		extraData,
	)

	if err != nil || !enabled || welcomeMsg == nil {
		return
	}

	msg := &HubMessage{
		MessageType: welcomeMsg.MessageType,
		Sender:      "system",
		Receiver:    client.UserID,
		Content:     welcomeMsg.Content,
		Data:        welcomeMsg.Data,
		CreateAt:    time.Now(),
		Priority:    welcomeMsg.Priority,
		Status:      MessageStatusSent,
	}

	if msg.Data == nil {
		msg.Data = make(map[string]interface{})
	}
	msg.Data["title"] = welcomeMsg.Title

	h.sendToClient(client, msg)
}

// ============================================================================
// æ‰©å±•èƒ½åŠ› - æ‰¹é‡æ“ä½œã€åˆ†ç»„ã€æŸ¥è¯¢ç­‰
// ============================================================================

// SendToMultipleUsers å‘é€æ¶ˆæ¯ç»™å¤šä¸ªç”¨æˆ·
func (h *Hub) SendToMultipleUsers(ctx context.Context, userIDs []string, msg *HubMessage) map[string]error {
	errors := make(map[string]error)
	for _, userID := range userIDs {
		result := h.SendToUserWithRetry(ctx, userID, msg)
		if result.FinalError != nil {
			errors[userID] = result.FinalError
		}
	}
	return errors
}

// BroadcastToGroup å‘é€æ¶ˆæ¯ç»™ç‰¹å®šç”¨æˆ·ç»„ï¼ˆæŒ‰ç”¨æˆ·ç±»å‹ï¼‰
func (h *Hub) BroadcastToGroup(ctx context.Context, userType UserType, msg *HubMessage) int {
	h.mutex.RLock()
	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.UserType == userType {
			clients = append(clients, client)
		}
	}
	h.mutex.RUnlock()

	count := 0
	for _, client := range clients {
		result := h.SendToUserWithRetry(ctx, client.UserID, msg)
		if result.FinalError == nil {
			count++
		}
	}
	return count
}

// BroadcastToRole å‘é€æ¶ˆæ¯ç»™ç‰¹å®šè§’è‰²ç”¨æˆ·
func (h *Hub) BroadcastToRole(ctx context.Context, role UserRole, msg *HubMessage) int {
	h.mutex.RLock()
	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.Role == role {
			clients = append(clients, client)
		}
	}
	h.mutex.RUnlock()

	count := 0
	for _, client := range clients {
		result := h.SendToUserWithRetry(ctx, client.UserID, msg)
		if result.FinalError == nil {
			count++
		}
	}
	return count
}

// GetClientsByUserType è·å–ç‰¹å®šç”¨æˆ·ç±»å‹çš„æ‰€æœ‰å®¢æˆ·ç«¯
func (h *Hub) GetClientsByUserType(userType UserType) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.UserType == userType {
			clients = append(clients, client)
		}
	}
	return clients
}

// GetClientsByRole è·å–ç‰¹å®šè§’è‰²çš„æ‰€æœ‰å®¢æˆ·ç«¯
func (h *Hub) GetClientsByRole(role UserRole) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.Role == role {
			clients = append(clients, client)
		}
	}
	return clients
}

// GetClientByID æ ¹æ®å®¢æˆ·ç«¯IDè·å–å®¢æˆ·ç«¯ä¿¡æ¯
func (h *Hub) GetClientByID(clientID string) *Client {
	h.mutex.RLock()
	client := h.clients[clientID]
	h.mutex.RUnlock()
	return client
}

// GetClientByUserID æ ¹æ®ç”¨æˆ·IDè·å–å®¢æˆ·ç«¯ä¿¡æ¯
func (h *Hub) GetClientByUserID(userID string) *Client {
	h.mutex.RLock()
	client := h.userToClient[userID]
	h.mutex.RUnlock()
	return client
}

// GetClientsCount è·å–æ€»å®¢æˆ·ç«¯è¿æ¥æ•°
func (h *Hub) GetClientsCount() int {
	h.mutex.RLock()
	defer h.mutex.RUnlock()
	return len(h.clients)
}

// GetUserStatus è·å–ç”¨æˆ·çŠ¶æ€
func (h *Hub) GetUserStatus(userID string) UserStatus {
	h.mutex.RLock()
	client, exists := h.userToClient[userID]
	h.mutex.RUnlock()

	if exists {
		return client.Status
	}
	return UserStatusOffline
}

// UpdateClientMetadata æ›´æ–°å®¢æˆ·ç«¯å…ƒæ•°æ®
func (h *Hub) UpdateClientMetadata(clientID string, key string, value interface{}) error {
	h.mutex.RLock()
	client, exists := h.clients[clientID]
	h.mutex.RUnlock()

	if !exists {
		return errorx.NewError(ErrTypeClientNotFound, "client_id: %s", clientID)
	}

	if client.Metadata == nil {
		client.Metadata = make(map[string]interface{})
	}
	client.Metadata[key] = value
	return nil
}

// GetClientMetadata è·å–å®¢æˆ·ç«¯å…ƒæ•°æ®
func (h *Hub) GetClientMetadata(clientID string, key string) (interface{}, bool) {
	h.mutex.RLock()
	client, exists := h.clients[clientID]
	h.mutex.RUnlock()

	if !exists || client.Metadata == nil {
		return nil, false
	}
	val, ok := client.Metadata[key]
	return val, ok
}

// DisconnectUser ä¸»åŠ¨æ–­å¼€ç”¨æˆ·è¿æ¥
func (h *Hub) DisconnectUser(userID string, reason string) error {
	h.mutex.RLock()
	client, exists := h.userToClient[userID]
	h.mutex.RUnlock()

	if !exists {
		return errorx.NewError(ErrTypeUserNotFound, "user_id: %s", userID)
	}

	if client.Conn != nil {
		client.Conn.Close()
	}
	return nil
}

// DisconnectClient ä¸»åŠ¨æ–­å¼€ç‰¹å®šå®¢æˆ·ç«¯
func (h *Hub) DisconnectClient(clientID string, reason string) error {
	h.mutex.RLock()
	client, exists := h.clients[clientID]
	h.mutex.RUnlock()

	if !exists {
		return errorx.NewError(ErrTypeClientNotFound, "client_id: %s", clientID)
	}

	if client.Conn != nil {
		client.Conn.Close()
	}
	return nil
}

// GetUptime è·å–Hubè¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
func (h *Hub) GetUptime() int64 {
	// å¦‚æœæœ‰ statsRepoï¼Œä» Redis è·å–ç²¾ç¡®çš„å¯åŠ¨æ—¶é—´
	if h.statsRepo != nil {
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
		defer cancel()

		nodeStats, err := h.statsRepo.GetNodeStats(ctx, h.nodeID)
		if err == nil && nodeStats != nil && nodeStats.StartTime != 0 {
			return time.Now().Unix() - nodeStats.StartTime
		}
	}

	// å¦‚æœæ²¡æœ‰ statsRepo æˆ–è·å–å¤±è´¥ï¼Œä½¿ç”¨ Hub å¯åŠ¨æ—¶é—´
	if h.startTime.IsZero() {
		return 0
	}
	return int64(time.Since(h.startTime).Seconds())
}

// GetMessageQueue è·å–æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦
func (h *Hub) GetMessageQueue() int {
	return len(h.pendingMessages)
}

// GetClientsByDepartment æŒ‰éƒ¨é—¨è·å–å®¢æˆ·ç«¯
func (h *Hub) GetClientsByDepartment(dept Department) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.Department == dept {
			clients = append(clients, client)
		}
	}
	return clients
}

// GetAgentStats è·å–åº§å¸­ç»Ÿè®¡
func (h *Hub) GetAgentStats() map[string]interface{} {
	h.mutex.RLock()
	agentCount := len(h.agentClients)
	h.mutex.RUnlock()

	stats := map[string]interface{}{
		"total_agents": agentCount,
		"agents":       make([]map[string]interface{}, 0),
	}

	h.mutex.RLock()
	agents := make([]map[string]interface{}, 0)
	for _, client := range h.agentClients {
		agents = append(agents, map[string]interface{}{
			"agent_id":    client.ID,
			"user_id":     client.UserID,
			"status":      client.Status,
			"department":  client.Department,
			"max_tickets": client.MaxTickets,
			"last_seen":   client.LastSeen,
		})
	}
	h.mutex.RUnlock()

	stats["agents"] = agents
	return stats
}

// ============================================================================
// é«˜çº§æ‰©å±•åŠŸèƒ½ - æ¶ˆæ¯è¿‡æ»¤ã€æ‰¹å¤„ç†ã€æ¡ä»¶æ¨é€ç­‰
// ============================================================================

// SendConditional æ¡ä»¶å‘é€æ¶ˆæ¯ - æ ¹æ®è‡ªå®šä¹‰æ¡ä»¶å‘é€ç»™åŒ¹é…çš„ç”¨æˆ·
func (h *Hub) SendConditional(ctx context.Context, condition func(*Client) bool, msg *HubMessage) int {
	h.mutex.RLock()
	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if condition(client) {
			clients = append(clients, client)
		}
	}
	h.mutex.RUnlock()

	count := 0
	for _, client := range clients {
		result := h.SendToUserWithRetry(ctx, client.UserID, msg)
		if result.FinalError == nil {
			count++
		}
	}
	return count
}

// BatchSendToUsers æ‰¹é‡å‘é€æ¶ˆæ¯ç»™å¤šä¸ªç”¨æˆ·ï¼ˆæ”¯æŒé™æµï¼‰
func (h *Hub) BatchSendToUsers(ctx context.Context, userIDs []string, msg *HubMessage, batchSize int) map[string]error {
	errors := make(map[string]error)

	if batchSize <= 0 {
		batchSize = 100
	}

	for i := 0; i < len(userIDs); i += batchSize {
		end := i + batchSize
		if end > len(userIDs) {
			end = len(userIDs)
		}

		for _, userID := range userIDs[i:end] {
			if result := h.SendToUserWithRetry(ctx, userID, msg); result.FinalError != nil {
				errors[userID] = result.FinalError
			}
		}

		// æ‰¹æ¬¡é—´éš”ï¼Œé¿å…å µå¡
		select {
		case <-ctx.Done():
			return errors
		case <-time.After(10 * time.Millisecond):
		}
	}

	return errors
}

// GetClientsWithStatus è·å–ç‰¹å®šçŠ¶æ€çš„æ‰€æœ‰å®¢æˆ·ç«¯
func (h *Hub) GetClientsWithStatus(status UserStatus) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.Status == status {
			clients = append(clients, client)
		}
	}
	return clients
}

// GetOnlineUsersCount è·å–åœ¨çº¿ç”¨æˆ·æ€»æ•°
func (h *Hub) GetOnlineUsersCount() int {
	return len(h.GetOnlineUsers())
}

// GetConnectionsByUserID æ ¹æ®ç”¨æˆ·IDè·å–æ‰€æœ‰è¿æ¥ï¼ˆåŒ…æ‹¬å¤šç«¯ç™»å½•ï¼‰
func (h *Hub) GetConnectionsByUserID(userID string) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.UserID == userID {
			clients = append(clients, client)
		}
	}
	return clients
}

// KickOffUser è¸¢æ‰ç”¨æˆ·æ‰€æœ‰è¿æ¥
func (h *Hub) KickOffUser(userID string, reason string) int {
	clients := h.GetConnectionsByUserID(userID)

	// è®°å½•è¸¢å‡ºæ“ä½œå¼€å§‹
	h.logger.InfoKV("å¼€å§‹è¸¢å‡ºç”¨æˆ·æ‰€æœ‰è¿æ¥",
		"user_id", userID,
		"reason", reason,
		"connection_count", len(clients),
	)

	for _, client := range clients {
		h.logger.InfoKV("å®¢æˆ·ç«¯è¢«è¸¢ä¸‹çº¿", "client_id", client.ID, "user_id", userID)
		if client.Conn != nil {
			client.Conn.Close()
		}
	}

	// è®°å½•è¸¢å‡ºç»“æœ
	h.logger.InfoKV("ç”¨æˆ·è¸¢å‡ºæ“ä½œå®Œæˆ",
		"user_id", userID,
		"reason", reason,
		"kicked_connections", len(clients),
	)

	return len(clients)
}

// LimitUserConnections é™åˆ¶ç”¨æˆ·æœ€å¤§è¿æ¥æ•°ï¼Œæ–­å¼€è¶…å‡ºçš„è¿æ¥
func (h *Hub) LimitUserConnections(userID string, maxConnections int) int {
	clients := h.GetConnectionsByUserID(userID)
	if len(clients) <= maxConnections {
		h.logger.DebugKV("ç”¨æˆ·è¿æ¥æ•°åœ¨é™åˆ¶èŒƒå›´å†…",
			"user_id", userID,
			"current_connections", len(clients),
			"max_connections", maxConnections,
		)
		return 0
	}

	// è®°å½•è¿æ¥é™åˆ¶æ“ä½œ
	h.logger.WarnKV("ç”¨æˆ·è¿æ¥æ•°è¶…é™ï¼Œå¼€å§‹æ–­å¼€æ—§è¿æ¥",
		"user_id", userID,
		"current_connections", len(clients),
		"max_connections", maxConnections,
		"to_disconnect", len(clients)-maxConnections,
	)

	// ä¿ç•™æœ€æ–°çš„è¿æ¥ï¼Œæ–­å¼€æ—§çš„
	kicked := 0
	for i := 0; i < len(clients)-maxConnections; i++ {
		h.logger.WarnKV("è¿æ¥æ•°é™åˆ¶è¸¢ä¸‹çº¿", "client_id", clients[i].ID, "user_id", userID, "kicked_index", i)
		if clients[i].Conn != nil {
			clients[i].Conn.Close()
			kicked++
		}
	}

	// è®°å½•é™åˆ¶ç»“æœ
	h.logger.InfoKV("ç”¨æˆ·è¿æ¥é™åˆ¶å®Œæˆ",
		"user_id", userID,
		"max_connections", maxConnections,
		"disconnected_count", kicked,
		"remaining_connections", len(clients)-kicked,
	)

	return kicked
}

// ScheduleMessage å®šæ—¶å‘é€æ¶ˆæ¯
func (h *Hub) ScheduleMessage(ctx context.Context, userID string, msg *HubMessage, delay time.Duration) {
	go func() {
		select {
		case <-time.After(delay):
			h.SendToUserWithRetry(ctx, userID, msg)
		case <-ctx.Done():
		}
	}()
}

// BroadcastAfterDelay å»¶è¿Ÿå¹¿æ’­æ¶ˆæ¯
func (h *Hub) BroadcastAfterDelay(ctx context.Context, msg *HubMessage, delay time.Duration) {
	go func() {
		select {
		case <-time.After(delay):
			h.Broadcast(ctx, msg)
		case <-ctx.Done():
		}
	}()
}

// GetClientsByClientType æŒ‰å®¢æˆ·ç«¯ç±»å‹è·å–å®¢æˆ·ç«¯
func (h *Hub) GetClientsByClientType(clientType ClientType) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	clients := make([]*Client, 0)
	for _, client := range h.clients {
		if client.ClientType == clientType {
			clients = append(clients, client)
		}
	}
	return clients
}

// GetConnectionInfo è·å–è¿æ¥è¯¦ç»†ä¿¡æ¯
func (h *Hub) GetConnectionInfo(clientID string) map[string]interface{} {
	h.mutex.RLock()
	client, exists := h.clients[clientID]
	h.mutex.RUnlock()

	if !exists {
		return nil
	}

	return map[string]interface{}{
		"client_id":   client.ID,
		"user_id":     client.UserID,
		"user_type":   client.UserType.String(),
		"role":        client.Role.String(),
		"status":      client.Status.String(),
		"department":  client.Department.String(),
		"client_type": client.ClientType.String(),
		"last_seen":   client.LastSeen,
		"node_id":     client.NodeID,
		"max_tickets": client.MaxTickets,
	}
}

// GetAllConnectionsInfo è·å–æ‰€æœ‰è¿æ¥è¯¦ç»†ä¿¡æ¯
func (h *Hub) GetAllConnectionsInfo() []map[string]interface{} {
	h.mutex.RLock()
	clients := make([]*Client, 0, len(h.clients))
	for _, client := range h.clients {
		clients = append(clients, client)
	}
	h.mutex.RUnlock()

	infos := make([]map[string]interface{}, 0)
	for _, client := range clients {
		infos = append(infos, h.GetConnectionInfo(client.ID))
	}
	return infos
}

// SendWithCallback å‘é€æ¶ˆæ¯å¹¶æ³¨å†Œå›è°ƒï¼ˆç”¨äºå¤„ç†ACKæˆ–è¶…æ—¶ï¼‰
func (h *Hub) SendWithCallback(ctx context.Context, userID string, msg *HubMessage,
	timeout time.Duration, onSuccess func(), onError func(error)) {
	go func() {
		ackMsg, err := h.SendToUserWithAck(ctx, userID, msg, timeout, 1)

		select {
		case <-time.After(timeout):
			if onError != nil {
				onError(ErrMessageDeliveryTimeout)
			}
		case <-ctx.Done():
			if onError != nil {
				onError(ctx.Err())
			}
		default:
			if err != nil {
				if onError != nil {
					onError(err)
				}
			} else if ackMsg != nil && ackMsg.Status == "success" {
				if onSuccess != nil {
					onSuccess()
				}
			}
		}
	}()
}

// ResetClientStatus é‡ç½®å®¢æˆ·ç«¯çŠ¶æ€
func (h *Hub) ResetClientStatus(clientID string, status UserStatus) error {
	h.mutex.RLock()
	client, exists := h.clients[clientID]
	h.mutex.RUnlock()

	if !exists {
		return errorx.NewError(ErrTypeClientNotFound, "client_id: %s", clientID)
	}

	client.Status = status
	return nil
}

// GetClientStats è·å–å•ä¸ªå®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯
func (h *Hub) GetClientStats(clientID string) map[string]interface{} {
	info := h.GetConnectionInfo(clientID)
	if info == nil {
		return nil
	}

	return map[string]interface{}{
		"connection_info":     info,
		"connection_duration": time.Since(info["last_seen"].(time.Time)),
	}
}

// FilterClients æŒ‰æ¡ä»¶è¿‡æ»¤å®¢æˆ·ç«¯
func (h *Hub) FilterClients(predicate func(*Client) bool) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	result := make([]*Client, 0)
	for _, client := range h.clients {
		if predicate(client) {
			result = append(result, client)
		}
	}
	return result
}

// SendToClientsWithRetry å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯åˆ—è¡¨ï¼Œæ”¯æŒå¤±è´¥é‡è¯•
func (h *Hub) SendToClientsWithRetry(ctx context.Context, clients []*Client, msg *HubMessage,
	maxRetry int) (success int, failed int) {
	for _, client := range clients {
		retryInstance := retry.NewRetryWithCtx(ctx).
			SetAttemptCount(maxRetry).
			SetInterval(h.config.BaseDelay).
			SetConditionFunc(h.isRetryableError)

		err := retryInstance.Do(func() error {
			result := h.SendToUserWithRetry(ctx, client.UserID, msg)
			return result.FinalError
		})

		if err == nil {
			success++
		} else {
			failed++
		}
	}
	return
}

// GetHubHealth è·å–Hubå¥åº·çŠ¶æ€
func (h *Hub) GetHubHealth() map[string]interface{} {
	h.mutex.RLock()
	wsCount := len(h.clients)
	h.mutex.RUnlock()

	h.sseMutex.RLock()
	sseCount := len(h.sseClients)
	h.sseMutex.RUnlock()

	isShutdown := h.shutdown.Load()

	return map[string]interface{}{
		"status":            "healthy",
		"is_running":        !isShutdown,
		"websocket_count":   wsCount,
		"sse_count":         sseCount,
		"total_connections": wsCount + sseCount,
	}
}

// ClearExpiredConnections æ¸…ç†è¶…æ—¶è¿æ¥
func (h *Hub) ClearExpiredConnections(timeout time.Duration) int {
	h.mutex.RLock()
	now := time.Now()
	expiredClients := make([]*Client, 0)
	for _, client := range h.clients {
		if now.Sub(client.LastSeen) > timeout {
			expiredClients = append(expiredClients, client)
		}
	}
	h.mutex.RUnlock()

	for _, client := range expiredClients {
		if client.Conn != nil {
			client.Conn.Close()
		}
	}
	return len(expiredClients)
}

// SendPriority æŒ‰ä¼˜å…ˆçº§å‘é€æ¶ˆæ¯ï¼ˆæ”¯æŒæ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„ä¼˜å…ˆçº§æ’åºï¼‰
func (h *Hub) SendPriority(ctx context.Context, userID string, msg *HubMessage, priority Priority) error {
	msg.Priority = priority
	return h.SendToUserWithRetry(ctx, userID, msg).FinalError
}

// BroadcastPriority æŒ‰ä¼˜å…ˆçº§å¹¿æ’­æ¶ˆæ¯
func (h *Hub) BroadcastPriority(ctx context.Context, msg *HubMessage, priority Priority) {
	msg.Priority = priority
	h.Broadcast(ctx, msg)
}

// ============================================================================
// ç»Ÿè®¡å’Œç›‘æ§ç›¸å…³æ–¹æ³•
// ============================================================================

// GetMessageStatisticsDetailed è·å–è¯¦ç»†çš„æ¶ˆæ¯ç»Ÿè®¡
func (h *Hub) GetMessageStatisticsDetailed() map[string]interface{} {
	// å¦‚æœè®¾ç½®äº†æ¶ˆæ¯è®°å½•ä»“åº“ï¼Œè·å–æ•°æ®åº“ç»Ÿè®¡
	var messageStats interface{}
	if h.messageRecordRepo != nil {
		if dbStats, err := h.GetMessageRecordStatistics(); err == nil {
			messageStats = dbStats
		} else {
			messageStats = map[string]interface{}{"error": err.Error()}
		}
	} else {
		messageStats = map[string]interface{}{"enabled": false}
	}

	return map[string]interface{}{
		"message_stats": messageStats,
		"hub_health":    h.GetHubHealth(),
		"agent_stats":   h.GetAgentStats(),
	}
}

// WaitForCondition ç­‰å¾…æ¡ä»¶æ»¡è¶³ï¼ˆç”¨äºæµ‹è¯•æˆ–åŒæ­¥ï¼‰
func (h *Hub) WaitForCondition(condition func() bool, timeout time.Duration) bool {
	deadline := time.Now().Add(timeout)
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	for {
		if condition() {
			return true
		}

		<-ticker.C
		if time.Now().After(deadline) {
			return false
		}
	}
}

// ============================================================================
// VIPç­‰çº§ç›¸å…³æ–¹æ³•
// ============================================================================

// SendToVIPUsers å‘é€æ¶ˆæ¯ç»™æŒ‡å®šVIPç­‰çº§åŠä»¥ä¸Šç”¨æˆ·
func (h *Hub) SendToVIPUsers(ctx context.Context, minVIPLevel VIPLevel, msg *HubMessage) int {
	return h.SendConditional(ctx, func(c *Client) bool {
		return c.VIPLevel.GetLevel() >= minVIPLevel.GetLevel()
	}, msg)
}

// SendToExactVIPLevel å‘é€æ¶ˆæ¯ç»™æŒ‡å®šVIPç­‰çº§ç”¨æˆ·
func (h *Hub) SendToExactVIPLevel(ctx context.Context, vipLevel VIPLevel, msg *HubMessage) int {
	return h.SendConditional(ctx, func(c *Client) bool {
		return c.VIPLevel == vipLevel
	}, msg)
}

// SendWithVIPPriority æ ¹æ®ç”¨æˆ·VIPç­‰çº§è‡ªåŠ¨è®¾ç½®æ¶ˆæ¯ä¼˜å…ˆçº§
func (h *Hub) SendWithVIPPriority(ctx context.Context, userID string, msg *HubMessage) error {
	// æ ¹æ®ç”¨æˆ·VIPç­‰çº§è®¾ç½®æ¶ˆæ¯ä¼˜å…ˆçº§
	client, exists := h.userToClient[userID]
	if exists {
		// æ ¹æ®VIPç­‰çº§è‡ªåŠ¨è°ƒæ•´ä¼˜å…ˆçº§
		vipLevel := client.VIPLevel.GetLevel()
		if vipLevel >= 6 { // V6-V8
			msg.Priority = PriorityHigh
		} else if vipLevel >= 3 { // V3-V5
			msg.Priority = PriorityNormal
		} else { // V0-V2
			msg.Priority = PriorityLow
		}
	}

	return h.SendToUserWithRetry(ctx, userID, msg).FinalError
}

// SendToUserWithClassification ä½¿ç”¨å®Œæ•´åˆ†ç±»ç³»ç»Ÿå‘é€æ¶ˆæ¯
func (h *Hub) SendToUserWithClassification(ctx context.Context, userID string, msg *HubMessage,
	classification *MessageClassification) error {

	// è®¾ç½®æ¶ˆæ¯åˆ†ç±»ä¿¡æ¯
	if classification != nil {
		msg.MessageType = classification.Type

		// æ ¹æ®åˆ†ç±»è®¡ç®—ä¼˜å…ˆçº§
		finalScore := classification.GetFinalPriority()
		if finalScore >= 80 {
			msg.Priority = PriorityHigh
		} else if finalScore >= 50 {
			msg.Priority = PriorityNormal
		} else {
			msg.Priority = PriorityLow
		}

		// æ·»åŠ åˆ†ç±»ä¿¡æ¯åˆ°æ¶ˆæ¯æ•°æ®ä¸­
		if msg.Data == nil {
			msg.Data = make(map[string]interface{})
		}
		msg.Data["classification"] = classification
		msg.Data["priority_score"] = finalScore
		msg.Data["is_critical"] = classification.IsCriticalMessage()
	}

	return h.SendToUserWithRetry(ctx, userID, msg).FinalError
}

// GetVIPStatistics è·å–VIPç”¨æˆ·ç»Ÿè®¡
func (h *Hub) GetVIPStatistics() map[string]int {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	stats := make(map[string]int)

	// ç»Ÿè®¡å„VIPç­‰çº§ç”¨æˆ·æ•°é‡
	for _, level := range GetAllVIPLevels() {
		stats[string(level)] = 0
	}

	for _, client := range h.clients {
		if client.VIPLevel.IsValid() {
			stats[string(client.VIPLevel)]++
		}
	}

	stats["total_vip"] = 0
	for level, count := range stats {
		if level != "v0" && level != "total_vip" {
			stats["total_vip"] += count
		}
	}

	return stats
}

// FilterVIPClients ç­›é€‰VIPç”¨æˆ·å®¢æˆ·ç«¯
func (h *Hub) FilterVIPClients(minLevel VIPLevel) []*Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	var vipClients []*Client
	for _, client := range h.clients {
		if client.VIPLevel.GetLevel() >= minLevel.GetLevel() {
			vipClients = append(vipClients, client)
		}
	}

	return vipClients
}

// UpgradeVIPLevel å‡çº§ç”¨æˆ·VIPç­‰çº§
func (h *Hub) UpgradeVIPLevel(userID string, newLevel VIPLevel) bool {
	h.mutex.Lock()
	defer h.mutex.Unlock()

	client, exists := h.userToClient[userID]
	if !exists || !newLevel.IsValid() {
		return false
	}

	// åªå…è®¸å‡çº§ï¼Œä¸å…è®¸é™çº§
	if newLevel.GetLevel() > client.VIPLevel.GetLevel() {
		client.VIPLevel = newLevel
		return true
	}

	return false
}

// SendToVIPWithPriority æ ¹æ®VIPç­‰çº§ä¼˜å…ˆå‘é€
func (h *Hub) SendToVIPWithPriority(ctx context.Context, vipLevel VIPLevel, msg *HubMessage) int {
	// VIPæ¶ˆæ¯ä¼˜å…ˆçº§æ›´é«˜
	if vipLevel.GetLevel() >= 5 {
		msg.Priority = PriorityHigh
	} else if vipLevel.GetLevel() >= 3 {
		msg.Priority = PriorityNormal
	}

	return h.SendConditional(ctx, func(c *Client) bool {
		return c.VIPLevel.GetLevel() >= vipLevel.GetLevel()
	}, msg)
}

// å®‰å…¨çš„æŸ¥è¯¢æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•å’Œç›‘æ§
// GetUserClient è·å–ç”¨æˆ·å¯¹åº”çš„å®¢æˆ·ç«¯
func (h *Hub) GetUserClient(userID string) *Client {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	return h.userToClient[userID]
}

// GetClientCount è·å–å½“å‰è¿æ¥çš„å®¢æˆ·ç«¯æ•°é‡
func (h *Hub) GetClientCount() int {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	return len(h.clients)
}

// HasClient æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šIDçš„å®¢æˆ·ç«¯
func (h *Hub) HasClient(clientID string) bool {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	_, exists := h.clients[clientID]
	return exists
}

// HasUserClient æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šç”¨æˆ·IDçš„å®¢æˆ·ç«¯
func (h *Hub) HasUserClient(userID string) bool {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	_, exists := h.userToClient[userID]
	return exists
}

// HasSSEClient æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šç”¨æˆ·IDçš„SSEè¿æ¥
func (h *Hub) HasSSEClient(userID string) bool {
	h.sseMutex.RLock()
	defer h.sseMutex.RUnlock()

	_, exists := h.sseClients[userID]
	return exists
}

// HasAgentClient æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šç”¨æˆ·IDçš„ä»£ç†å®¢æˆ·ç«¯
func (h *Hub) HasAgentClient(userID string) bool {
	h.mutex.RLock()
	defer h.mutex.RUnlock()

	_, exists := h.agentClients[userID]
	return exists
}

// ============================================================================
// å›è°ƒæ³¨å†Œæ–¹æ³• - Hub çº§åˆ«çš„äº‹ä»¶å›è°ƒ (ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ OnXxx æ–¹æ³•)
// ============================================================================
// æ³¨æ„ï¼šè¿™äº›æ˜¯æœåŠ¡ç«¯ Hub çº§åˆ«çš„å›è°ƒï¼Œç”¨äºå¤„ç†å…¨å±€äº‹ä»¶
// å®¢æˆ·ç«¯çº§åˆ«çš„å›è°ƒè¯·å‚è€ƒ wsc.go ä¸­çš„ Wsc ç»“æ„ä½“

// OnHeartbeatTimeout æ³¨å†Œå¿ƒè·³è¶…æ—¶å›è°ƒå‡½æ•°
// å½“å®¢æˆ·ç«¯å¿ƒè·³è¶…æ—¶æ—¶ä¼šè°ƒç”¨æ­¤å›è°ƒ
//
// å‚æ•°:
//   - clientID: è¶…æ—¶çš„å®¢æˆ·ç«¯ID
//   - userID: è¶…æ—¶çš„ç”¨æˆ·ID
//   - lastHeartbeat: æœ€åä¸€æ¬¡å¿ƒè·³æ—¶é—´
//
// ç¤ºä¾‹:
//
//	hub.OnHeartbeatTimeout(func(clientID, userID string, lastHeartbeat time.Time) {
//	    log.Printf("å®¢æˆ·ç«¯ %s å¿ƒè·³è¶…æ—¶", clientID)
//	    æ›´æ–°æ•°æ®åº“ã€æ¸…ç†ç¼“å­˜ç­‰
//	})
func (h *Hub) OnHeartbeatTimeout(callback HeartbeatTimeoutCallback) {
	h.heartbeatTimeoutHandler = callback
}

// IsUserOnline æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨çº¿ï¼ˆä» Redis æŸ¥è¯¢)
// å‚æ•°:
//   - userID: ç”¨æˆ·ID
//
// è¿”å›:
//   - bool: æ˜¯å¦åœ¨çº¿
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) IsUserOnline(userID string) (bool, error) {
	// ä¼˜å…ˆæ£€æŸ¥æœ¬åœ° WebSocket è¿æ¥
	h.mutex.RLock()
	for _, client := range h.clients {
		if client.UserID == userID {
			h.mutex.RUnlock()
			return true, nil
		}
	}
	h.mutex.RUnlock()

	// æ£€æŸ¥ SSE è¿æ¥
	h.sseMutex.RLock()
	_, sseExists := h.sseClients[userID]
	h.sseMutex.RUnlock()

	if sseExists {
		return true, nil
	}

	// å¦‚æœæœ‰ Redis repositoryï¼Œæ£€æŸ¥å…¶ä»–èŠ‚ç‚¹
	if h.onlineStatusRepo != nil {
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
		defer cancel()
		return h.onlineStatusRepo.IsOnline(ctx, userID)
	}

	return false, nil
}

// GetUserOnlineInfo è·å–ç”¨æˆ·åœ¨çº¿ä¿¡æ¯
// å‚æ•°:
//   - userID: ç”¨æˆ·ID
//
// è¿”å›:
//   - *OnlineClientInfo: åœ¨çº¿ä¿¡æ¯
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetUserOnlineInfo(userID string) (*OnlineClientInfo, error) {
	// ä¼˜å…ˆæ£€æŸ¥æœ¬åœ° WebSocket å®¢æˆ·ç«¯
	h.mutex.RLock()
	for _, client := range h.clients {
		if client.UserID == userID {
			info := &OnlineClientInfo{
				UserID:   client.UserID,
				NodeID:   h.nodeID,
				UserType: client.UserType,
				Status:   client.Status,
				LastSeen: client.LastSeen,
				ClientID: client.ID,
			}
			h.mutex.RUnlock()
			return info, nil
		}
	}
	h.mutex.RUnlock()

	// æ£€æŸ¥ SSE å®¢æˆ·ç«¯
	h.sseMutex.RLock()
	if sseConn, exists := h.sseClients[userID]; exists {
		info := &OnlineClientInfo{
			UserID:   userID,
			NodeID:   h.nodeID,
			UserType: UserTypeCustomer,
			Status:   UserStatusOnline,
			LastSeen: sseConn.LastActive,
			ClientID: "sse-" + userID,
		}
		h.sseMutex.RUnlock()
		return info, nil
	}
	h.sseMutex.RUnlock()

	// å¦‚æœæœ‰ repositoryï¼ŒæŸ¥è¯¢å…¶ä»–èŠ‚ç‚¹
	if h.onlineStatusRepo != nil {
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
		defer cancel()
		return h.onlineStatusRepo.GetOnlineInfo(ctx, userID)
	}

	return nil, nil
}

// GetAllOnlineUserIDs è·å–æ‰€æœ‰åœ¨çº¿ç”¨æˆ·IDåˆ—è¡¨
// è¿”å›:
//   - []string: ç”¨æˆ·IDåˆ—è¡¨
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetAllOnlineUserIDs() ([]string, error) {
	// å¦‚æœæ²¡æœ‰ repositoryï¼Œè¿”å›æœ¬åœ°åœ¨çº¿ç”¨æˆ·
	if h.onlineStatusRepo == nil {
		userIDs := make(map[string]bool)

		// æ”¶é›† WebSocket ç”¨æˆ·
		h.mutex.RLock()
		for _, client := range h.clients {
			userIDs[client.UserID] = true
		}
		h.mutex.RUnlock()

		// æ”¶é›† SSE ç”¨æˆ·
		h.sseMutex.RLock()
		for userID := range h.sseClients {
			userIDs[userID] = true
		}
		h.sseMutex.RUnlock()

		result := make([]string, 0, len(userIDs))
		for userID := range userIDs {
			result = append(result, userID)
		}
		return result, nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()
	return h.onlineStatusRepo.GetAllOnlineUsers(ctx)
}

// GetOnlineUsersByNode è·å–æŒ‡å®šèŠ‚ç‚¹çš„åœ¨çº¿ç”¨æˆ·
// å‚æ•°:
//   - nodeID: èŠ‚ç‚¹ID
//
// è¿”å›:
//   - []string: ç”¨æˆ·IDåˆ—è¡¨
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetOnlineUsersByNode(nodeID string) ([]string, error) {
	// å¦‚æœæŸ¥è¯¢æœ¬èŠ‚ç‚¹ä¸”æ²¡æœ‰ repositoryï¼Œè¿”å›æœ¬åœ°æ•°æ®
	if nodeID == h.nodeID && h.onlineStatusRepo == nil {
		return h.GetAllOnlineUserIDs()
	}

	if h.onlineStatusRepo == nil {
		return nil, ErrOnlineStatusRepositoryNotSet
	}

	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()
	return h.onlineStatusRepo.GetOnlineUsersByNode(ctx, nodeID)
}

// GetOnlineUsersByType æ ¹æ®ç”¨æˆ·ç±»å‹è·å–åœ¨çº¿ç”¨æˆ·
// å‚æ•°:
//   - userType: ç”¨æˆ·ç±»å‹
//
// è¿”å›:
//   - []string: ç”¨æˆ·IDåˆ—è¡¨
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetOnlineUsersByType(userType UserType) ([]string, error) {
	// å¦‚æœæ²¡æœ‰ repositoryï¼Œåœ¨æœ¬åœ°ç­›é€‰
	if h.onlineStatusRepo == nil {
		userIDs := make([]string, 0)

		h.mutex.RLock()
		for _, client := range h.clients {
			if client.UserType == userType {
				userIDs = append(userIDs, client.UserID)
			}
		}
		h.mutex.RUnlock()

		return userIDs, nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
	defer cancel()
	return h.onlineStatusRepo.GetOnlineUsersByType(ctx, userType)
}

// GetOnlineUserCount è·å–åœ¨çº¿ç”¨æˆ·æ€»æ•°
// è¿”å›:
//   - int64: åœ¨çº¿ç”¨æˆ·æ•°é‡
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetOnlineUserCount() (int64, error) {
	// å¦‚æœæ²¡æœ‰ repositoryï¼Œè¿”å›æœ¬åœ°åœ¨çº¿ç”¨æˆ·æ•°
	if h.onlineStatusRepo == nil {
		userIDs, _ := h.GetAllOnlineUserIDs()
		return int64(len(userIDs)), nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.onlineStatusRepo.GetOnlineCount(ctx)
}

// GetOnlineUserCountByType è·å–æŒ‡å®šç±»å‹çš„åœ¨çº¿ç”¨æˆ·æ•°
// å‚æ•°:
//   - userType: ç”¨æˆ·ç±»å‹
//
// è¿”å›:
//   - int64: åœ¨çº¿ç”¨æˆ·æ•°é‡
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetOnlineUserCountByType(userType UserType) (int64, error) {
	users, err := h.GetOnlineUsersByType(userType)
	if err != nil {
		return 0, err
	}
	return int64(len(users)), nil
}

// UpdateUserHeartbeat æ›´æ–°ç”¨æˆ·å¿ƒè·³æ—¶é—´
// å‚æ•°:
//   - userID: ç”¨æˆ·ID
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) UpdateUserHeartbeat(userID string) error {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.onlineStatusRepo.UpdateHeartbeat(ctx, userID)
}

// SyncOnlineStatusToRedis åŒæ­¥å½“å‰æ‰€æœ‰åœ¨çº¿ç”¨æˆ·åˆ° Redis
// ç”¨äº Hub å¯åŠ¨æ—¶æˆ–å®šæœŸåŒæ­¥
func (h *Hub) SyncOnlineStatusToRedis() error {
	h.mutex.RLock()
	clients := make(map[string]*Client, len(h.clients))
	for id, client := range h.clients {
		clients[id] = client
	}
	h.mutex.RUnlock()

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	users := make(map[string]*OnlineClientInfo, len(clients))
	for _, client := range clients {
		users[client.UserID] = &OnlineClientInfo{
			ClientID:      client.ID,
			UserID:        client.UserID,
			UserType:      client.UserType,
			NodeID:        h.nodeID,
			NodeIP:        h.config.NodeIP,
			ClientIP:      client.ClientIP,
			ConnectTime:   time.Now(),
			LastSeen:      client.LastSeen,
			LastHeartbeat: client.LastHeartbeat,
			ClientType:    client.ClientType,
			Status:        client.Status,
			Metadata:      client.Metadata,
		}
	}

	return h.onlineStatusRepo.BatchSetOnline(ctx, users, 0)
}

// recordMessageToDatabase å°†æ¶ˆæ¯è®°å½•åˆ°æ•°æ®åº“ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
func (h *Hub) recordMessageToDatabase(msg *HubMessage, err error) {
	// å¼‚æ­¥è®°å½•ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
	go func() {
		defer func() {
			if r := recover(); r != nil {
				h.logger.ErrorKV("æ¶ˆæ¯è®°å½•å¤±è´¥",
					"message_id", msg.ID,
					"panic", r,
				)
			}
		}()

		// è¿‡æ»¤ä¸éœ€è¦è®°å½•çš„æ¶ˆæ¯ç±»å‹
		if msg.MessageType.ShouldSkipDatabaseRecord() {
			return
		}

		// ç¡®å®šåˆå§‹çŠ¶æ€
		status := MessageSendStatusPending
		failureReason := FailureReason("")
		errorMsg := ""

		if err != nil {
			status = MessageSendStatusFailed
			errorMsg = err.Error()

			// æ ¹æ®é”™è¯¯ç±»å‹è®¾ç½®å¤±è´¥åŸå› 
			switch {
			case IsQueueFullError(err):
				failureReason = FailureReasonQueueFull
			case IsUserOfflineError(err):
				failureReason = FailureReasonUserOffline
			case IsSendTimeoutError(err):
				failureReason = FailureReasonSendTimeout
			case IsAckTimeoutError(err):
				failureReason = FailureReasonAckTimeout
			default:
				failureReason = FailureReasonUnknown
			}
		}

		// è·å–å®¢æˆ·ç«¯IPï¼ˆå¦‚æœå­˜åœ¨ï¼‰
		clientIP := ""
		if msg.Sender != "" {
			h.mutex.RLock()
			if client, exists := h.userToClient[msg.Sender]; exists {
				clientIP = client.ClientIP
				if clientIP == "" && client.Conn != nil {
					// å¦‚æœClientIPæœªè®¾ç½®ï¼Œä»è¿æ¥ä¸­è·å–
					if remoteAddr := client.Conn.RemoteAddr(); remoteAddr != nil {
						clientIP = remoteAddr.String()
					}
				}
			}
			h.mutex.RUnlock()
		}

		// åˆ›å»ºæ¶ˆæ¯è®°å½•
		record := &MessageSendRecord{
			Status:        status,
			CreateTime:    time.Now(),
			MaxRetry:      h.config.MaxRetries,
			FailureReason: failureReason,
			ErrorMessage:  errorMsg,
			NodeIP:        h.config.NodeIP, // è®°å½•æœåŠ¡å™¨èŠ‚ç‚¹IP
			ClientIP:      clientIP,        // è®°å½•å®¢æˆ·ç«¯IP
		}

		// è®¾ç½®æ¶ˆæ¯æ•°æ®
		if setErr := record.SetMessage(msg); setErr != nil {
			h.logger.ErrorKV("åºåˆ—åŒ–æ¶ˆæ¯å¤±è´¥",
				"message_id", msg.ID,
				"error", setErr,
			)
			return
		}

		// ä¿å­˜åˆ°æ•°æ®åº“
		if h.messageRecordRepo != nil {
			if createErr := h.messageRecordRepo.Create(record); createErr != nil {
				h.logger.ErrorKV("ä¿å­˜æ¶ˆæ¯è®°å½•å¤±è´¥",
					"message_id", msg.ID,
					"error", createErr,
				)
			} else {
				h.logger.DebugKV("æ¶ˆæ¯è®°å½•å·²ä¿å­˜",
					"message_id", msg.ID,
					"status", status,
					"record_id", record.ID,
				)
			}
		}
	}()
}

// updateMessageSendStatus è§£ææ¶ˆæ¯å¹¶æ›´æ–°å‘é€çŠ¶æ€ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
func (h *Hub) updateMessageSendStatus(messageData []byte, status MessageSendStatus, reason FailureReason, errorMsg string) {
	// å¼‚æ­¥æ›´æ–°ï¼Œé¿å…é˜»å¡å‘é€æµç¨‹
	go func() {
		defer func() {
			if r := recover(); r != nil {
				h.logger.ErrorKV("æ›´æ–°æ¶ˆæ¯çŠ¶æ€å¤±è´¥",
					"panic", r,
				)
			}
		}()

		// è§£ææ¶ˆæ¯è·å–ID
		var msg HubMessage
		if err := json.Unmarshal(messageData, &msg); err != nil {
			h.logger.ErrorKV("è§£ææ¶ˆæ¯å¤±è´¥",
				"error", err,
				"data_size", len(messageData),
			)
			return
		}

		// è¿‡æ»¤ä¸éœ€è¦è®°å½•çš„æ¶ˆæ¯ç±»å‹
		if msg.MessageType.ShouldSkipDatabaseRecord() {
			return
		}

		// ğŸ”¥ ä½¿ç”¨ go-toolbox retry ç»„ä»¶ï¼šç­‰å¾…è®°å½•åˆ›å»ºå®Œæˆï¼ˆæœ€å¤šé‡è¯•3æ¬¡ï¼Œæ¯æ¬¡ç­‰å¾…50msï¼‰
		ctx := context.Background()
		retryInstance := retry.NewRetryWithCtx(ctx).
			SetAttemptCount(3).
			SetInterval(50 * time.Millisecond)

		attemptNum := 0
		updateErr := retryInstance.Do(func() error {
			attemptNum++
			err := h.messageRecordRepo.UpdateStatus(msg.ID, status, reason, errorMsg)
			if err == nil {
				h.logger.DebugKV("æ¶ˆæ¯çŠ¶æ€å·²æ›´æ–°",
					"message_id", msg.ID,
					"status", status,
					"attempt", attemptNum,
				)
			}
			return err
		})

		// æ‰€æœ‰é‡è¯•å¤±è´¥åï¼Œé™çº§ä¸º Debug æ—¥å¿—ï¼ˆæŸäº›æ¶ˆæ¯å¦‚å¹¿æ’­/ç³»ç»Ÿæ¶ˆæ¯å¯èƒ½æ²¡æœ‰è®°å½•ï¼‰
		if updateErr != nil {
			h.logger.DebugKV("æ›´æ–°æ¶ˆæ¯è®°å½•çŠ¶æ€å¤±è´¥(è®°å½•å¯èƒ½ä¸å­˜åœ¨æˆ–ä¸ºç³»ç»Ÿæ¶ˆæ¯)",
				"message_id", msg.ID,
				"status", status,
				"error", updateErr,
				"attempts", attemptNum,
			)
		}
	}()
}

// ============================================================================
// æ¶ˆæ¯è®°å½•æŸ¥è¯¢æ¥å£ - æš´éœ²ç»™å¤–éƒ¨ä½¿ç”¨
// ============================================================================

// QueryMessageRecord æŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - messageID: æ¶ˆæ¯ID
//
// è¿”å›:
//   - *MessageSendRecord: æ¶ˆæ¯è®°å½•
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) QueryMessageRecord(messageID string) (*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindByMessageID(messageID)
}

// QueryMessageRecordsBySender æ ¹æ®å‘é€è€…æŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - sender: å‘é€è€…ID
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryMessageRecordsBySender(sender string, limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindBySender(sender, limit)
}

// QueryMessageRecordsByReceiver æ ¹æ®æ¥æ”¶è€…æŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - receiver: æ¥æ”¶è€…ID
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryMessageRecordsByReceiver(receiver string, limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindByReceiver(receiver, limit)
}

// QueryMessageRecordsByNodeIP æ ¹æ®èŠ‚ç‚¹IPæŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - nodeIP: æœåŠ¡å™¨èŠ‚ç‚¹IP
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryMessageRecordsByNodeIP(nodeIP string, limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindByNodeIP(nodeIP, limit)
}

// QueryMessageRecordsByClientIP æ ¹æ®å®¢æˆ·ç«¯IPæŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - clientIP: å®¢æˆ·ç«¯IPåœ°å€
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryMessageRecordsByClientIP(clientIP string, limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindByClientIP(clientIP, limit)
}

// QueryMessageRecordsByStatus æ ¹æ®çŠ¶æ€æŸ¥è¯¢æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - status: æ¶ˆæ¯çŠ¶æ€
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryMessageRecordsByStatus(status MessageSendStatus, limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindByStatus(status, limit)
}

// QueryRetryableMessageRecords æŸ¥è¯¢å¯é‡è¯•çš„æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryRetryableMessageRecords(limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindRetryable(limit)
}

// QueryExpiredMessageRecords æŸ¥è¯¢è¿‡æœŸçš„æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
func (h *Hub) QueryExpiredMessageRecords(limit int) ([]*MessageSendRecord, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.FindExpired(limit)
}

// ============================================================================
// æ¶ˆæ¯è®°å½•æ›´æ–°æ¥å£
// ============================================================================

// UpdateMessageRecordStatus æ›´æ–°æ¶ˆæ¯è®°å½•çŠ¶æ€
// å‚æ•°:
//   - messageID: æ¶ˆæ¯ID
//   - status: æ–°çŠ¶æ€
//   - reason: å¤±è´¥åŸå› ï¼ˆå¯é€‰ï¼‰
//   - errorMsg: é”™è¯¯æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
func (h *Hub) UpdateMessageRecordStatus(messageID string, status MessageSendStatus, reason FailureReason, errorMsg string) error {
	if h.messageRecordRepo == nil {
		return ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.UpdateStatus(messageID, status, reason, errorMsg)
}

// UpdateMessageRecord æ›´æ–°æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - record: è¦æ›´æ–°çš„æ¶ˆæ¯è®°å½•
func (h *Hub) UpdateMessageRecord(record *MessageSendRecord) error {
	if h.messageRecordRepo == nil {
		return ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.Update(record)
}

// ============================================================================
// æ¶ˆæ¯è®°å½•åˆ é™¤æ¥å£
// ============================================================================

// DeleteMessageRecord åˆ é™¤æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - id: è®°å½•ID
func (h *Hub) DeleteMessageRecord(id uint) error {
	if h.messageRecordRepo == nil {
		return ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.Delete(id)
}

// DeleteMessageRecordByMessageID æ ¹æ®æ¶ˆæ¯IDåˆ é™¤æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - messageID: æ¶ˆæ¯ID
func (h *Hub) DeleteMessageRecordByMessageID(messageID string) error {
	if h.messageRecordRepo == nil {
		return ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.DeleteByMessageID(messageID)
}

// CleanupOldMessageRecords æ¸…ç†æ—§çš„æ¶ˆæ¯è®°å½•
// å‚æ•°:
//   - before: åœ¨æ­¤æ—¶é—´ä¹‹å‰çš„è®°å½•ä¼šè¢«æ¸…ç†
//
// è¿”å›:
//   - int64: è¢«æ¸…ç†çš„è®°å½•æ•°é‡
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) CleanupOldMessageRecords(before time.Time) (int64, error) {
	if h.messageRecordRepo == nil {
		return 0, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.CleanupOld(before)
}

// ============================================================================
// æ¶ˆæ¯è®°å½•ç»Ÿè®¡æ¥å£
// ============================================================================

// GetMessageRecordStatistics è·å–æ¶ˆæ¯è®°å½•ç»Ÿè®¡ä¿¡æ¯
// è¿”å›:
//   - map[string]int64: ç»Ÿè®¡æ•°æ®ï¼ŒåŒ…å«å„ç§çŠ¶æ€çš„æ¶ˆæ¯æ•°é‡
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetMessageRecordStatistics() (map[string]int64, error) {
	if h.messageRecordRepo == nil {
		return nil, ErrRecordRepositoryNotSet
	}
	return h.messageRecordRepo.GetStatistics()
}

// ============================================================================
// è´Ÿè½½ç®¡ç†æ¥å£
// ============================================================================

// SetAgentWorkload è®¾ç½®å®¢æœå·¥ä½œè´Ÿè½½
// å‚æ•°:
//   - agentID: å®¢æœID
//   - workload: å·¥ä½œè´Ÿè½½å€¼
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) SetAgentWorkload(agentID string, workload int64) error {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè·³è¿‡è®¾ç½®å®¢æœè´Ÿè½½")
		return nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.SetAgentWorkload(ctx, agentID, workload)
}

// GetAgentWorkload è·å–å®¢æœå·¥ä½œè´Ÿè½½
// å‚æ•°:
//   - agentID: å®¢æœID
//
// è¿”å›:
//   - int64: å·¥ä½œè´Ÿè½½å€¼
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetAgentWorkload(agentID string) (int64, error) {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè¿”å›0")
		return 0, nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.GetAgentWorkload(ctx, agentID)
}

// IncrementAgentWorkload å¢åŠ å®¢æœå·¥ä½œè´Ÿè½½
// å‚æ•°:
//   - agentID: å®¢æœID
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) IncrementAgentWorkload(agentID string) error {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè·³è¿‡å¢åŠ å®¢æœè´Ÿè½½")
		return nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.IncrementAgentWorkload(ctx, agentID)
}

// DecrementAgentWorkload å‡å°‘å®¢æœå·¥ä½œè´Ÿè½½
// å‚æ•°:
//   - agentID: å®¢æœID
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) DecrementAgentWorkload(agentID string) error {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè·³è¿‡å‡å°‘å®¢æœè´Ÿè½½")
		return nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.DecrementAgentWorkload(ctx, agentID)
}

// GetLeastLoadedAgent è·å–è´Ÿè½½æœ€å°çš„åœ¨çº¿å®¢æœ
// è¿”å›:
//   - string: å®¢æœID
//   - int64: å·¥ä½œè´Ÿè½½å€¼
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetLeastLoadedAgent() (string, int64, error) {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®")
		return "", 0, fmt.Errorf("workload repository not set")
	}

	// è·å–åœ¨çº¿å®¢æœåˆ—è¡¨
	onlineAgents, err := h.GetOnlineUsersByType(UserTypeAgent)
	if err != nil {
		return "", 0, fmt.Errorf("failed to get online agents: %w", err)
	}

	if len(onlineAgents) == 0 {
		return "", 0, fmt.Errorf("no online agents available")
	}

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.GetLeastLoadedAgent(ctx, onlineAgents)
}

// RemoveAgentWorkload ç§»é™¤å®¢æœè´Ÿè½½è®°å½•ï¼ˆå®¢æœç¦»çº¿æ—¶è°ƒç”¨ï¼‰
// å‚æ•°:
//   - agentID: å®¢æœID
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) RemoveAgentWorkload(agentID string) error {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè·³è¿‡ç§»é™¤å®¢æœè´Ÿè½½")
		return nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.RemoveAgentWorkload(ctx, agentID)
}

// GetAllAgentWorkloads è·å–æ‰€æœ‰å®¢æœçš„è´Ÿè½½ä¿¡æ¯
// å‚æ•°:
//   - limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œ0è¡¨ç¤ºè¿”å›å…¨éƒ¨
//
// è¿”å›:
//   - []WorkloadInfo: è´Ÿè½½ä¿¡æ¯åˆ—è¡¨
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) GetAllAgentWorkloads(limit int64) ([]WorkloadInfo, error) {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®")
		return nil, fmt.Errorf("workload repository not set")
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.GetAllAgentWorkloads(ctx, limit)
}

// BatchSetAgentWorkload æ‰¹é‡è®¾ç½®å®¢æœè´Ÿè½½
// å‚æ•°:
//   - workloads: å®¢æœIDåˆ°è´Ÿè½½å€¼çš„æ˜ å°„
//
// è¿”å›:
//   - error: é”™è¯¯ä¿¡æ¯
func (h *Hub) BatchSetAgentWorkload(workloads map[string]int64) error {
	if h.workloadRepo == nil {
		h.logger.Warn("è´Ÿè½½ç®¡ç†ä»“åº“æœªè®¾ç½®ï¼Œè·³è¿‡æ‰¹é‡è®¾ç½®å®¢æœè´Ÿè½½")
		return nil
	}
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	return h.workloadRepo.BatchSetAgentWorkload(ctx, workloads)
}
