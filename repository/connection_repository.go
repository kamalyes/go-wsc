/*
 * @Author: kamalyes 501893067@qq.com
 * @Date: 2025-12-19 00:00:00
 * @LastEditors: kamalyes 501893067@qq.com
 * @LastEditTime: 2025-12-28 15:00:16
 * @FilePath: \go-wsc\repository\connection_repository.go
 * @Description: WebSocketè¿æ¥è®°å½•ä»“åº“æ¥å£
 *
 * Copyright (c) 2025 by kamalyes, All Rights Reserved.
 */

package repository

import (
	"context"
	"fmt"
	"time"

	wscconfig "github.com/kamalyes/go-config/pkg/wsc"
	"github.com/kamalyes/go-logger"
	"github.com/kamalyes/go-toolbox/pkg/syncx"
	"github.com/kamalyes/go-wsc/models"
	"gorm.io/gorm"
)

// ConnectionRecordRepository WebSocketè¿æ¥è®°å½•ä»“å‚¨æ¥å£
// ç”¨äºæŒä¹…åŒ–è¿æ¥å†å²è®°å½•ï¼Œæ”¯æŒå®¡è®¡ã€ç»Ÿè®¡åˆ†æç­‰åŠŸèƒ½
type ConnectionRecordRepository interface {
	// ========== åŸºç¡€CRUDæ“ä½œ ==========

	// Create åˆ›å»ºè¿æ¥è®°å½•
	Create(ctx context.Context, record *models.ConnectionRecord) error

	// Update æ›´æ–°è¿æ¥è®°å½•
	Update(ctx context.Context, record *models.ConnectionRecord) error

	// UpdateByConnectionID æ ¹æ®è¿æ¥IDæ›´æ–°è®°å½•
	UpdateByConnectionID(ctx context.Context, connectionID string, updates map[string]interface{}) error

	// GetByConnectionID æ ¹æ®è¿æ¥IDè·å–è®°å½•
	GetByConnectionID(ctx context.Context, connectionID string) (*models.ConnectionRecord, error)

	// GetByID æ ¹æ®ä¸»é”®IDè·å–è®°å½•
	GetByID(ctx context.Context, id uint64) (*models.ConnectionRecord, error)

	// Delete åˆ é™¤è¿æ¥è®°å½•
	Delete(ctx context.Context, id uint64) error

	// ========== æ–­å¼€è¿æ¥æ“ä½œ ==========

	// MarkDisconnected æ ‡è®°è¿æ¥ä¸ºå·²æ–­å¼€
	MarkDisconnected(ctx context.Context, connectionID string, reason models.DisconnectReason, code int, message string) error

	// MarkForcedOffline æ ‡è®°ä¸ºå¼ºåˆ¶ä¸‹çº¿
	MarkForcedOffline(ctx context.Context, connectionID string, reason string) error

	// ========== ç»Ÿè®¡æ›´æ–°æ“ä½œ ==========

	// IncrementMessageStats å¢åŠ æ¶ˆæ¯ç»Ÿè®¡
	IncrementMessageStats(ctx context.Context, connectionID string, sent, received int64) error

	// IncrementBytesStats å¢åŠ å­—èŠ‚ç»Ÿè®¡
	IncrementBytesStats(ctx context.Context, connectionID string, sent, received int64) error

	// UpdatePingStats æ›´æ–°Pingå»¶è¿Ÿç»Ÿè®¡
	UpdatePingStats(ctx context.Context, connectionID string, pingMs float64) error

	// IncrementReconnect å¢åŠ é‡è¿æ¬¡æ•°
	IncrementReconnect(ctx context.Context, connectionID string) error

	// AddError è®°å½•é”™è¯¯
	AddError(ctx context.Context, connectionID string, err error) error

	// UpdateHeartbeat æ›´æ–°å¿ƒè·³æ—¶é—´
	UpdateHeartbeat(ctx context.Context, connectionID string, pingTime, pongTime *time.Time) error

	// ========== æŸ¥è¯¢æ“ä½œ ==========

	// GetActiveByUserID è·å–ç”¨æˆ·çš„æ´»è·ƒè¿æ¥è®°å½•
	GetActiveByUserID(ctx context.Context, userID string) ([]*models.ConnectionRecord, error)

	// GetByUserID è·å–ç”¨æˆ·çš„æ‰€æœ‰è¿æ¥è®°å½•
	GetByUserID(ctx context.Context, userID string, limit int, offset int) ([]*models.ConnectionRecord, error)

	// GetActiveByNodeID è·å–èŠ‚ç‚¹çš„æ´»è·ƒè¿æ¥è®°å½•
	GetActiveByNodeID(ctx context.Context, nodeID string) ([]*models.ConnectionRecord, error)

	// GetByNodeID è·å–èŠ‚ç‚¹çš„æ‰€æœ‰è¿æ¥è®°å½•
	GetByNodeID(ctx context.Context, nodeID string, limit int, offset int) ([]*models.ConnectionRecord, error)

	// ListActive è·å–æ‰€æœ‰æ´»è·ƒè¿æ¥
	ListActive(ctx context.Context, limit int, offset int) ([]*models.ConnectionRecord, error)

	// ListByTimeRange è·å–æ—¶é—´èŒƒå›´å†…çš„è¿æ¥è®°å½•
	ListByTimeRange(ctx context.Context, startTime, endTime time.Time, limit int, offset int) ([]*models.ConnectionRecord, error)

	// ========== ç»Ÿè®¡åˆ†ææ“ä½œ ==========

	// CountActiveConnections ç»Ÿè®¡æ´»è·ƒè¿æ¥æ•°
	CountActiveConnections(ctx context.Context) (int64, error)

	// CountByUserID ç»Ÿè®¡ç”¨æˆ·çš„è¿æ¥æ¬¡æ•°
	CountByUserID(ctx context.Context, userID string) (int64, error)

	// CountByNodeID ç»Ÿè®¡èŠ‚ç‚¹çš„è¿æ¥æ¬¡æ•°
	CountByNodeID(ctx context.Context, nodeID string) (int64, error)

	// CountByTimeRange ç»Ÿè®¡æ—¶é—´èŒƒå›´å†…çš„è¿æ¥æ¬¡æ•°
	CountByTimeRange(ctx context.Context, startTime, endTime time.Time) (int64, error)

	// GetAverageConnectionDuration è·å–å¹³å‡è¿æ¥æ—¶é•¿
	GetAverageConnectionDuration(ctx context.Context, startTime, endTime time.Time) (float64, error)

	// GetConnectionStats è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯
	GetConnectionStats(ctx context.Context, startTime, endTime time.Time) (*ConnectionStats, error)

	// GetUserConnectionStats è·å–ç”¨æˆ·è¿æ¥ç»Ÿè®¡
	GetUserConnectionStats(ctx context.Context, userID string, startTime, endTime time.Time) (*UserConnectionStats, error)

	// GetNodeConnectionStats è·å–èŠ‚ç‚¹è¿æ¥ç»Ÿè®¡
	GetNodeConnectionStats(ctx context.Context, nodeID string, startTime, endTime time.Time) (*NodeConnectionStats, error)

	// ========== å¼‚å¸¸æ£€æµ‹æ“ä½œ ==========

	// GetAbnormalConnections è·å–å¼‚å¸¸è¿æ¥è®°å½•
	GetAbnormalConnections(ctx context.Context, limit int, offset int) ([]*models.ConnectionRecord, error)

	// GetHighErrorRateConnections è·å–é«˜é”™è¯¯ç‡è¿æ¥
	GetHighErrorRateConnections(ctx context.Context, errorThreshold int, limit int) ([]*models.ConnectionRecord, error)

	// GetFrequentReconnectUsers è·å–é¢‘ç¹é‡è¿çš„ç”¨æˆ·
	GetFrequentReconnectUsers(ctx context.Context, reconnectThreshold int, timeRange time.Duration) ([]UserReconnectStats, error)

	// ========== æ‰¹é‡æ“ä½œ ==========

	// BatchCreate æ‰¹é‡åˆ›å»ºè¿æ¥è®°å½•
	BatchCreate(ctx context.Context, records []*models.ConnectionRecord) error

	// BatchUpdateActive æ‰¹é‡æ›´æ–°æ´»è·ƒçŠ¶æ€
	BatchUpdateActive(ctx context.Context, connectionIDs []string, isActive bool) error

	// BatchDelete æ‰¹é‡åˆ é™¤è®°å½•
	BatchDelete(ctx context.Context, ids []uint64) error

	// ========== æ¸…ç†æ“ä½œ ==========

	// CleanupOldRecords æ¸…ç†æ—§è®°å½•
	CleanupOldRecords(ctx context.Context, before time.Time) (int64, error)

	// ArchiveOldRecords å½’æ¡£æ—§è®°å½•
	// processor: å¤„ç†å‡½æ•°ï¼Œæ¥æ”¶è¯»å–åˆ°çš„è®°å½•è¿›è¡Œè‡ªå®šä¹‰å¤„ç†ï¼ˆå¦‚å†™å…¥å½’æ¡£è¡¨ã€å¯¼å‡ºæ–‡ä»¶ç­‰ï¼‰
	// è¿”å›å¤„ç†çš„è®°å½•æ•°å’Œé”™è¯¯
	ArchiveOldRecords(ctx context.Context, before time.Time, processor func([]*models.ConnectionRecord) error) (int64, error)

	// Close å…³é—­ä»“åº“ï¼Œåœæ­¢åå°ä»»åŠ¡
	Close() error
}

// ========== ç»Ÿè®¡ç»“æ„ä½“å®šä¹‰ ==========

// ConnectionStats è¿æ¥ç»Ÿè®¡ä¿¡æ¯
type ConnectionStats struct {
	TotalConnections      int64   `json:"total_connections"`       // æ€»è¿æ¥æ•°
	ActiveConnections     int64   `json:"active_connections"`      // æ´»è·ƒè¿æ¥æ•°
	AverageDuration       float64 `json:"average_duration"`        // å¹³å‡è¿æ¥æ—¶é•¿(ç§’)
	TotalMessagesSent     int64   `json:"total_messages_sent"`     // æ€»å‘é€æ¶ˆæ¯æ•°
	TotalMessagesReceived int64   `json:"total_messages_received"` // æ€»æ¥æ”¶æ¶ˆæ¯æ•°
	TotalBytesSent        int64   `json:"total_bytes_sent"`        // æ€»å‘é€å­—èŠ‚æ•°
	TotalBytesReceived    int64   `json:"total_bytes_received"`    // æ€»æ¥æ”¶å­—èŠ‚æ•°
	AveragePingMs         float64 `json:"average_ping_ms"`         // å¹³å‡Pingå»¶è¿Ÿ
	AbnormalRate          float64 `json:"abnormal_rate"`           // å¼‚å¸¸æ–­å¼€ç‡
	ReconnectRate         float64 `json:"reconnect_rate"`          // é‡è¿ç‡
}

// UserConnectionStats ç”¨æˆ·è¿æ¥ç»Ÿè®¡
type UserConnectionStats struct {
	UserID                   string    `json:"user_id"`
	TotalConnections         int64     `json:"total_connections"`
	ActiveConnections        int64     `json:"active_connections"`
	AverageDuration          float64   `json:"average_duration"`
	LastConnectedAt          time.Time `json:"last_connected_at"`
	TotalReconnects          int64     `json:"total_reconnects"`
	TotalErrors              int64     `json:"total_errors"`
	AverageConnectionQuality float64   `json:"average_connection_quality"`
}

// NodeConnectionStats èŠ‚ç‚¹è¿æ¥ç»Ÿè®¡
type NodeConnectionStats struct {
	NodeID                string  `json:"node_id"`
	TotalConnections      int64   `json:"total_connections"`
	ActiveConnections     int64   `json:"active_connections"`
	AverageDuration       float64 `json:"average_duration"`
	TotalMessagesSent     int64   `json:"total_messages_sent"`
	TotalMessagesReceived int64   `json:"total_messages_received"`
	AveragePingMs         float64 `json:"average_ping_ms"`
	ErrorRate             float64 `json:"error_rate"`
}

// UserReconnectStats ç”¨æˆ·é‡è¿ç»Ÿè®¡
type UserReconnectStats struct {
	UserID          string    `json:"user_id"`
	ReconnectCount  int64     `json:"reconnect_count"`
	LastReconnectAt time.Time `json:"last_reconnect_at"`
}

// connectionRecordRepositoryImpl WebSocketè¿æ¥è®°å½•ä»“å‚¨å®ç°
type connectionRecordRepositoryImpl struct {
	db         *gorm.DB
	logger     logger.ILogger
	cancelFunc context.CancelFunc // ç”¨äºåœæ­¢æ¸…ç†ä»»åŠ¡
}

// NewConnectionRecordRepository åˆ›å»ºè¿æ¥è®°å½•ä»“å‚¨å®ä¾‹
// å‚æ•°:
//   - db: GORM æ•°æ®åº“å®ä¾‹
//   - config: è¿æ¥è®°å½•é…ç½®å¯¹è±¡ï¼ˆå¯é€‰ï¼Œä¼  nil åˆ™ä¸å¯ç”¨è‡ªåŠ¨æ¸…ç†ï¼‰
//   - log: æ—¥å¿—è®°å½•å™¨
func NewConnectionRecordRepository(db *gorm.DB, config *wscconfig.ConnectionRecord, log logger.ILogger) ConnectionRecordRepository {
	// åˆ›å»ºå¯å–æ¶ˆçš„ context
	ctx, cancel := context.WithCancel(context.Background())

	repo := &connectionRecordRepositoryImpl{
		db:         db,
		logger:     log,
		cancelFunc: cancel,
	}

	// ğŸ§¹ å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡ï¼ˆæ ¹æ®é…ç½®ï¼‰
	if config != nil && config.EnableAutoCleanup && config.CleanupDaysAgo > 0 {
		go repo.startCleanupScheduler(ctx, config.CleanupDaysAgo)
	}

	return repo
}

// ========== åŸºç¡€CRUDæ“ä½œ ==========

// Create åˆ›å»ºè¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) Create(ctx context.Context, record *models.ConnectionRecord) error {
	return r.db.WithContext(ctx).Create(record).Error
}

// Update æ›´æ–°è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) Update(ctx context.Context, record *models.ConnectionRecord) error {
	return r.db.WithContext(ctx).Save(record).Error
}

// UpdateByConnectionID æ ¹æ®è¿æ¥IDæ›´æ–°è®°å½•
func (r *connectionRecordRepositoryImpl) UpdateByConnectionID(ctx context.Context, connectionID string, updates map[string]interface{}) error {
	return r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connection_id = ?", connectionID).
		Updates(updates).Error
}

// GetByConnectionID æ ¹æ®è¿æ¥IDè·å–è®°å½•
func (r *connectionRecordRepositoryImpl) GetByConnectionID(ctx context.Context, connectionID string) (*models.ConnectionRecord, error) {
	var record models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("connection_id = ?", connectionID).
		First(&record).Error
	if err != nil {
		return nil, err
	}
	return &record, nil
}

// GetByID æ ¹æ®ä¸»é”®IDè·å–è®°å½•
func (r *connectionRecordRepositoryImpl) GetByID(ctx context.Context, id uint64) (*models.ConnectionRecord, error) {
	var record models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("id = ?", id).
		First(&record).Error
	if err != nil {
		return nil, err
	}
	return &record, nil
}

// Delete åˆ é™¤è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) Delete(ctx context.Context, id uint64) error {
	return r.db.WithContext(ctx).
		Delete(&models.ConnectionRecord{}, id).Error
}

// ========== æ–­å¼€è¿æ¥æ“ä½œ ==========

// MarkDisconnected æ ‡è®°è¿æ¥ä¸ºå·²æ–­å¼€
func (r *connectionRecordRepositoryImpl) MarkDisconnected(ctx context.Context, connectionID string, reason models.DisconnectReason, code int, message string) error {
	now := time.Now()

	// è·å–è¿æ¥è®°å½•ä»¥è®¡ç®—æŒç»­æ—¶é•¿
	record, err := r.GetByConnectionID(ctx, connectionID)
	if err != nil {
		return err
	}

	duration := int64(now.Sub(record.ConnectedAt).Seconds())
	isAbnormal := reason != models.DisconnectReasonClientRequest && reason != models.DisconnectReasonServerShutdown

	updates := map[string]interface{}{
		"disconnected_at":    now,
		"disconnect_reason":  string(reason),
		"disconnect_code":    code,
		"disconnect_message": message,
		"duration":           duration,
		"is_active":          false,
		"is_abnormal":        isAbnormal,
	}

	return r.UpdateByConnectionID(ctx, connectionID, updates)
}

// MarkForcedOffline æ ‡è®°ä¸ºå¼ºåˆ¶ä¸‹çº¿
func (r *connectionRecordRepositoryImpl) MarkForcedOffline(ctx context.Context, connectionID string, reason string) error {
	return r.MarkDisconnected(ctx, connectionID, models.DisconnectReasonForceOffline, 4000, reason)
}

// ========== ç»Ÿè®¡æ›´æ–°æ“ä½œ ==========

// IncrementMessageStats å¢åŠ æ¶ˆæ¯ç»Ÿè®¡
func (r *connectionRecordRepositoryImpl) IncrementMessageStats(ctx context.Context, connectionID string, sent, received int64) error {
	return r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connection_id = ?", connectionID).
		Updates(map[string]interface{}{
			"messages_sent":     gorm.Expr("messages_sent + ?", sent),
			"messages_received": gorm.Expr("messages_received + ?", received),
		}).Error
}

// IncrementBytesStats å¢åŠ å­—èŠ‚ç»Ÿè®¡
func (r *connectionRecordRepositoryImpl) IncrementBytesStats(ctx context.Context, connectionID string, sent, received int64) error {
	return r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connection_id = ?", connectionID).
		Updates(map[string]interface{}{
			"bytes_sent":     gorm.Expr("bytes_sent + ?", sent),
			"bytes_received": gorm.Expr("bytes_received + ?", received),
		}).Error
}

// UpdatePingStats æ›´æ–°Pingå»¶è¿Ÿç»Ÿè®¡
func (r *connectionRecordRepositoryImpl) UpdatePingStats(ctx context.Context, connectionID string, pingMs float64) error {
	record, err := r.GetByConnectionID(ctx, connectionID)
	if err != nil {
		return err
	}

	// è®¡ç®—æ–°çš„å¹³å‡å€¼
	newAverage := pingMs
	if record.AveragePingMs > 0 {
		newAverage = (record.AveragePingMs + pingMs) / 2
	}

	// æ›´æ–°æœ€å¤§æœ€å°å€¼
	newMax := record.MaxPingMs
	if newMax == 0 || pingMs > newMax {
		newMax = pingMs
	}

	newMin := record.MinPingMs
	if newMin == 0 || pingMs < newMin {
		newMin = pingMs
	}

	updates := map[string]interface{}{
		"average_ping_ms": newAverage,
		"max_ping_ms":     newMax,
		"min_ping_ms":     newMin,
	}

	return r.UpdateByConnectionID(ctx, connectionID, updates)
}

// IncrementReconnect å¢åŠ é‡è¿æ¬¡æ•°
func (r *connectionRecordRepositoryImpl) IncrementReconnect(ctx context.Context, connectionID string) error {
	return r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connection_id = ?", connectionID).
		Update("reconnect_count", gorm.Expr("reconnect_count + ?", 1)).Error
}

// AddError è®°å½•é”™è¯¯
func (r *connectionRecordRepositoryImpl) AddError(ctx context.Context, connectionID string, err error) error {
	if err == nil {
		return nil
	}

	now := time.Now()
	updates := map[string]interface{}{
		"error_count":   gorm.Expr("error_count + ?", 1),
		"last_error":    err.Error(),
		"last_error_at": now,
	}

	return r.UpdateByConnectionID(ctx, connectionID, updates)
}

// UpdateHeartbeat æ›´æ–°å¿ƒè·³æ—¶é—´
func (r *connectionRecordRepositoryImpl) UpdateHeartbeat(ctx context.Context, connectionID string, pingTime, pongTime *time.Time) error {
	updates := make(map[string]interface{})

	if pingTime != nil {
		updates["last_ping_at"] = pingTime
	}
	if pongTime != nil {
		updates["last_pong_at"] = pongTime
	}

	if len(updates) == 0 {
		return nil
	}

	return r.UpdateByConnectionID(ctx, connectionID, updates)
}

// ========== æŸ¥è¯¢æ“ä½œ ==========

// GetActiveByUserID è·å–ç”¨æˆ·çš„æ´»è·ƒè¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) GetActiveByUserID(ctx context.Context, userID string) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("user_id = ? AND is_active = ?", userID, true).
		Order("connected_at DESC").
		Find(&records).Error
	return records, err
}

// GetByUserID è·å–ç”¨æˆ·çš„æ‰€æœ‰è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) GetByUserID(ctx context.Context, userID string, limit int, offset int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("user_id = ?", userID).
		Order("connected_at DESC").
		Limit(limit).
		Offset(offset).
		Find(&records).Error
	return records, err
}

// GetActiveByNodeID è·å–èŠ‚ç‚¹çš„æ´»è·ƒè¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) GetActiveByNodeID(ctx context.Context, nodeID string) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("node_id = ? AND is_active = ?", nodeID, true).
		Order("connected_at DESC").
		Find(&records).Error
	return records, err
}

// GetByNodeID è·å–èŠ‚ç‚¹çš„æ‰€æœ‰è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) GetByNodeID(ctx context.Context, nodeID string, limit int, offset int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("node_id = ?", nodeID).
		Order("connected_at DESC").
		Limit(limit).
		Offset(offset).
		Find(&records).Error
	return records, err
}

// ListActive è·å–æ‰€æœ‰æ´»è·ƒè¿æ¥
func (r *connectionRecordRepositoryImpl) ListActive(ctx context.Context, limit int, offset int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("is_active = ?", true).
		Order("connected_at DESC").
		Limit(limit).
		Offset(offset).
		Find(&records).Error
	return records, err
}

// ListByTimeRange è·å–æ—¶é—´èŒƒå›´å†…çš„è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) ListByTimeRange(ctx context.Context, startTime, endTime time.Time, limit int, offset int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("connected_at BETWEEN ? AND ?", startTime, endTime).
		Order("connected_at DESC").
		Limit(limit).
		Offset(offset).
		Find(&records).Error
	return records, err
}

// ========== ç»Ÿè®¡åˆ†ææ“ä½œ ==========

// CountActiveConnections ç»Ÿè®¡æ´»è·ƒè¿æ¥æ•°
func (r *connectionRecordRepositoryImpl) CountActiveConnections(ctx context.Context) (int64, error) {
	var count int64
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("is_active = ?", true).
		Count(&count).Error
	return count, err
}

// CountByUserID ç»Ÿè®¡ç”¨æˆ·çš„è¿æ¥æ¬¡æ•°
func (r *connectionRecordRepositoryImpl) CountByUserID(ctx context.Context, userID string) (int64, error) {
	var count int64
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("user_id = ?", userID).
		Count(&count).Error
	return count, err
}

// CountByNodeID ç»Ÿè®¡èŠ‚ç‚¹çš„è¿æ¥æ¬¡æ•°
func (r *connectionRecordRepositoryImpl) CountByNodeID(ctx context.Context, nodeID string) (int64, error) {
	var count int64
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("node_id = ?", nodeID).
		Count(&count).Error
	return count, err
}

// CountByTimeRange ç»Ÿè®¡æ—¶é—´èŒƒå›´å†…çš„è¿æ¥æ¬¡æ•°
func (r *connectionRecordRepositoryImpl) CountByTimeRange(ctx context.Context, startTime, endTime time.Time) (int64, error) {
	var count int64
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connected_at BETWEEN ? AND ?", startTime, endTime).
		Count(&count).Error
	return count, err
}

// GetAverageConnectionDuration è·å–å¹³å‡è¿æ¥æ—¶é•¿
func (r *connectionRecordRepositoryImpl) GetAverageConnectionDuration(ctx context.Context, startTime, endTime time.Time) (float64, error) {
	var avgDuration float64
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connected_at BETWEEN ? AND ? AND duration > 0", startTime, endTime).
		Select("AVG(duration)").
		Scan(&avgDuration).Error
	return avgDuration, err
}

// GetConnectionStats è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯
func (r *connectionRecordRepositoryImpl) GetConnectionStats(ctx context.Context, startTime, endTime time.Time) (*ConnectionStats, error) {
	stats := &ConnectionStats{}

	// åŸºç¡€ç»Ÿè®¡æŸ¥è¯¢
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connected_at BETWEEN ? AND ?", startTime, endTime).
		Select(`
			COUNT(*) as total_connections,
			SUM(CASE WHEN is_active = true THEN 1 ELSE 0 END) as active_connections,
			AVG(CASE WHEN duration > 0 THEN duration ELSE NULL END) as average_duration,
			SUM(messages_sent) as total_messages_sent,
			SUM(messages_received) as total_messages_received,
			SUM(bytes_sent) as total_bytes_sent,
			SUM(bytes_received) as total_bytes_received,
			AVG(CASE WHEN average_ping_ms > 0 THEN average_ping_ms ELSE NULL END) as average_ping_ms
		`).
		Scan(stats).Error

	if err != nil {
		return nil, err
	}

	// è®¡ç®—å¼‚å¸¸ç‡
	if stats.TotalConnections > 0 {
		var abnormalCount int64
		r.db.WithContext(ctx).
			Model(&models.ConnectionRecord{}).
			Where("connected_at BETWEEN ? AND ? AND is_abnormal = ?", startTime, endTime, true).
			Count(&abnormalCount)
		stats.AbnormalRate = float64(abnormalCount) / float64(stats.TotalConnections) * 100
	}

	// è®¡ç®—é‡è¿ç‡
	var totalReconnects int64
	r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connected_at BETWEEN ? AND ?", startTime, endTime).
		Select("SUM(reconnect_count)").
		Scan(&totalReconnects)

	if stats.TotalConnections > 0 {
		stats.ReconnectRate = float64(totalReconnects) / float64(stats.TotalConnections) * 100
	}

	return stats, nil
}

// GetUserConnectionStats è·å–ç”¨æˆ·è¿æ¥ç»Ÿè®¡
func (r *connectionRecordRepositoryImpl) GetUserConnectionStats(ctx context.Context, userID string, startTime, endTime time.Time) (*UserConnectionStats, error) {
	stats := &UserConnectionStats{
		UserID: userID,
	}

	// åŸºç¡€ç»Ÿè®¡
	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("user_id = ? AND connected_at BETWEEN ? AND ?", userID, startTime, endTime).
		Select(`
			COUNT(*) as total_connections,
			SUM(CASE WHEN is_active = true THEN 1 ELSE 0 END) as active_connections,
			AVG(CASE WHEN duration > 0 THEN duration ELSE NULL END) as average_duration,
			MAX(connected_at) as last_connected_at,
			SUM(reconnect_count) as total_reconnects,
			SUM(error_count) as total_errors
		`).
		Scan(stats).Error

	if err != nil {
		return nil, err
	}

	// è®¡ç®—å¹³å‡è¿æ¥è´¨é‡
	var totalQuality float64
	var qualityCount int64
	records, _ := r.GetByUserID(ctx, userID, 100, 0)
	for _, record := range records {
		if record.ConnectedAt.After(startTime) && record.ConnectedAt.Before(endTime) {
			totalQuality += record.GetConnectionQuality()
			qualityCount++
		}
	}
	if qualityCount > 0 {
		stats.AverageConnectionQuality = totalQuality / float64(qualityCount)
	}

	return stats, nil
}

// GetNodeConnectionStats è·å–èŠ‚ç‚¹è¿æ¥ç»Ÿè®¡
func (r *connectionRecordRepositoryImpl) GetNodeConnectionStats(ctx context.Context, nodeID string, startTime, endTime time.Time) (*NodeConnectionStats, error) {
	stats := &NodeConnectionStats{
		NodeID: nodeID,
	}

	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("node_id = ? AND connected_at BETWEEN ? AND ?", nodeID, startTime, endTime).
		Select(`
			COUNT(*) as total_connections,
			SUM(CASE WHEN is_active = true THEN 1 ELSE 0 END) as active_connections,
			AVG(CASE WHEN duration > 0 THEN duration ELSE NULL END) as average_duration,
			SUM(messages_sent) as total_messages_sent,
			SUM(messages_received) as total_messages_received,
			AVG(CASE WHEN average_ping_ms > 0 THEN average_ping_ms ELSE NULL END) as average_ping_ms
		`).
		Scan(stats).Error

	if err != nil {
		return nil, err
	}

	// è®¡ç®—é”™è¯¯ç‡
	if stats.TotalConnections > 0 {
		var totalErrors int64
		r.db.WithContext(ctx).
			Model(&models.ConnectionRecord{}).
			Where("node_id = ? AND connected_at BETWEEN ? AND ?", nodeID, startTime, endTime).
			Select("SUM(error_count)").
			Scan(&totalErrors)

		totalMessages := stats.TotalMessagesSent + stats.TotalMessagesReceived
		if totalMessages > 0 {
			stats.ErrorRate = float64(totalErrors) / float64(totalMessages) * 100
		}
	}

	return stats, nil
}

// ========== å¼‚å¸¸æ£€æµ‹æ“ä½œ ==========

// GetAbnormalConnections è·å–å¼‚å¸¸è¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) GetAbnormalConnections(ctx context.Context, limit int, offset int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("is_abnormal = ?", true).
		Order("connected_at DESC").
		Limit(limit).
		Offset(offset).
		Find(&records).Error
	return records, err
}

// GetHighErrorRateConnections è·å–é«˜é”™è¯¯ç‡è¿æ¥
func (r *connectionRecordRepositoryImpl) GetHighErrorRateConnections(ctx context.Context, errorThreshold int, limit int) ([]*models.ConnectionRecord, error) {
	var records []*models.ConnectionRecord
	err := r.db.WithContext(ctx).
		Where("error_count >= ?", errorThreshold).
		Order("error_count DESC").
		Limit(limit).
		Find(&records).Error
	return records, err
}

// GetFrequentReconnectUsers è·å–é¢‘ç¹é‡è¿çš„ç”¨æˆ·
func (r *connectionRecordRepositoryImpl) GetFrequentReconnectUsers(ctx context.Context, reconnectThreshold int, timeRange time.Duration) ([]UserReconnectStats, error) {
	var stats []UserReconnectStats

	startTime := time.Now().Add(-timeRange)

	err := r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Select("user_id, SUM(reconnect_count) as reconnect_count, MAX(connected_at) as last_reconnect_at").
		Where("connected_at >= ?", startTime).
		Group("user_id").
		Having("SUM(reconnect_count) >= ?", reconnectThreshold).
		Order("reconnect_count DESC").
		Scan(&stats).Error

	return stats, err
}

// ========== æ‰¹é‡æ“ä½œ ==========

// BatchCreate æ‰¹é‡åˆ›å»ºè¿æ¥è®°å½•
func (r *connectionRecordRepositoryImpl) BatchCreate(ctx context.Context, records []*models.ConnectionRecord) error {
	if len(records) == 0 {
		return nil
	}

	// åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹1000æ¡
	batchSize := 1000
	for i := 0; i < len(records); i += batchSize {
		end := i + batchSize
		if end > len(records) {
			end = len(records)
		}

		if err := r.db.WithContext(ctx).Create(records[i:end]).Error; err != nil {
			return fmt.Errorf("batch create failed at index %d: %w", i, err)
		}
	}

	return nil
}

// BatchUpdateActive æ‰¹é‡æ›´æ–°æ´»è·ƒçŠ¶æ€
func (r *connectionRecordRepositoryImpl) BatchUpdateActive(ctx context.Context, connectionIDs []string, isActive bool) error {
	if len(connectionIDs) == 0 {
		return nil
	}

	return r.db.WithContext(ctx).
		Model(&models.ConnectionRecord{}).
		Where("connection_id IN ?", connectionIDs).
		Update("is_active", isActive).Error
}

// BatchDelete æ‰¹é‡åˆ é™¤è®°å½•
func (r *connectionRecordRepositoryImpl) BatchDelete(ctx context.Context, ids []uint64) error {
	if len(ids) == 0 {
		return nil
	}

	return r.db.WithContext(ctx).
		Delete(&models.ConnectionRecord{}, ids).Error
}

// ========== æ¸…ç†æ“ä½œ ==========

// CleanupOldRecords æ¸…ç†æ—§è®°å½•
func (r *connectionRecordRepositoryImpl) CleanupOldRecords(ctx context.Context, before time.Time) (int64, error) {
	result := r.db.WithContext(ctx).
		Where("connected_at < ? AND is_active = ?", before, false).
		Delete(&models.ConnectionRecord{})

	if result.Error != nil {
		return 0, result.Error
	}

	return result.RowsAffected, nil
}

// ArchiveOldRecords å½’æ¡£æ—§è®°å½•
// ä½¿ç”¨æ¸¸æ ‡åˆ†é¡µæ–¹å¼åˆ†æ‰¹æŸ¥è¯¢å¹¶å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ•°æ®åˆ°å†…å­˜
func (r *connectionRecordRepositoryImpl) ArchiveOldRecords(ctx context.Context, before time.Time, processor func([]*models.ConnectionRecord) error) (int64, error) {
	if processor == nil {
		return 0, fmt.Errorf("processor function cannot be nil")
	}

	batchSize := 1000
	totalProcessed := int64(0)
	lastID := uint64(0) // ä½¿ç”¨IDä½œä¸ºæ¸¸æ ‡ï¼Œæ¯”OFFSETåˆ†é¡µé«˜æ•ˆ

	for {
		var records []*models.ConnectionRecord
		query := r.db.WithContext(ctx).
			Where("connected_at < ? AND is_active = ?", before, false)

		// ä½¿ç”¨IDæ¸¸æ ‡åˆ†é¡µï¼Œé¿å…OFFSETå¸¦æ¥çš„æ€§èƒ½é—®é¢˜
		if lastID > 0 {
			query = query.Where("id > ?", lastID)
		}

		err := query.
			Order("id ASC").
			Limit(batchSize).
			Find(&records).Error

		if err != nil {
			return totalProcessed, fmt.Errorf("failed to fetch records: %w", err)
		}

		// æ²¡æœ‰æ›´å¤šè®°å½•äº†
		if len(records) == 0 {
			break
		}

		// è°ƒç”¨å¤„ç†å‡½æ•°å¤„ç†è¿™æ‰¹è®°å½•
		if err := processor(records); err != nil {
			return totalProcessed, fmt.Errorf("processor failed at last_id %d: %w", lastID, err)
		}

		totalProcessed += int64(len(records))

		// æ›´æ–°æ¸¸æ ‡ä¸ºæœ€åä¸€æ¡è®°å½•çš„ID
		lastID = records[len(records)-1].ID

		// å¦‚æœè¿”å›çš„è®°å½•æ•°å°‘äºæ‰¹æ¬¡å¤§å°ï¼Œè¯´æ˜å·²ç»å¤„ç†å®Œäº†
		if len(records) < batchSize {
			break
		}
	}

	return totalProcessed, nil
}

// startCleanupScheduler å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡ï¼ˆä½¿ç”¨ EventLoopï¼Œæ¯å¤©æ‰§è¡Œä¸€æ¬¡ï¼‰
func (r *connectionRecordRepositoryImpl) startCleanupScheduler(ctx context.Context, daysAgo int) {
	// ç«‹å³æ‰§è¡Œä¸€æ¬¡æ¸…ç†
	r.cleanupOldData(ctx, daysAgo)

	// ä½¿ç”¨ EventLoop ç®¡ç†å®šæ—¶ä»»åŠ¡
	syncx.NewEventLoop(ctx).
		// æ¯å¤©æ‰§è¡Œä¸€æ¬¡æ¸…ç†
		OnTicker(24*time.Hour, func() {
			r.cleanupOldData(ctx, daysAgo)
		}).
		// Panic å¤„ç†
		OnPanic(func(rec any) {
			r.logger.Errorf("âš ï¸ è¿æ¥è®°å½•æ¸…ç†ä»»åŠ¡ panic: %v", rec)
		}).
		// ä¼˜é›…å…³é—­
		OnShutdown(func() {
			r.logger.Info("ğŸ›‘ è¿æ¥è®°å½•æ¸…ç†ä»»åŠ¡å·²åœæ­¢")
		}).
		Run()
}

// cleanupOldData æ¸…ç†Nå¤©å‰çš„å†å²æ•°æ®
//
// è®¾è®¡è¯´æ˜ï¼š
//   - æ¸…ç†éæ´»è·ƒçš„å†å²è¿æ¥è®°å½•ï¼Œé‡Šæ”¾æ•°æ®åº“ç©ºé—´
//   - ä¿ç•™æ´»è·ƒè¿æ¥è®°å½•ï¼Œé¿å…è¯¯åˆ 
//
// å‚æ•°ï¼š
//   - daysAgo: æ¸…ç†å¤šå°‘å¤©å‰çš„æ•°æ®ï¼ˆä¾‹å¦‚ï¼š30 è¡¨ç¤ºæ¸…ç†30å¤©å‰çš„éæ´»è·ƒè¿æ¥è®°å½•ï¼‰
func (r *connectionRecordRepositoryImpl) cleanupOldData(ctx context.Context, daysAgo int) {
	if daysAgo <= 0 {
		return
	}

	// è®¡ç®—æ¸…ç†æ—¶é—´ç‚¹
	before := time.Now().AddDate(0, 0, -daysAgo)

	// æ¸…ç†æ—§è®°å½•
	deleted, err := r.CleanupOldRecords(ctx, before)
	if err != nil {
		r.logger.Warnf("âš ï¸ æ¸…ç†å†å²è¿æ¥è®°å½•å¤±è´¥: %v", err)
	} else if deleted > 0 {
		r.logger.Infof("ğŸ§¹ å·²æ¸…ç† %d å¤©å‰çš„å†å²è¿æ¥è®°å½•ï¼Œåˆ é™¤ %d æ¡", daysAgo, deleted)
	}
}

// Close å…³é—­ä»“åº“ï¼Œåœæ­¢åå°æ¸…ç†ä»»åŠ¡
func (r *connectionRecordRepositoryImpl) Close() error {
	if r.cancelFunc != nil {
		r.cancelFunc()
		r.logger.Info("ğŸ›‘ ConnectionRecordRepository å·²å…³é—­")
	}
	return nil
}
